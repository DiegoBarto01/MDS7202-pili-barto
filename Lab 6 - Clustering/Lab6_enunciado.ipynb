{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac9155b9f5e04400957a6f8bb3f6610c",
        "deepnote_cell_type": "markdown",
        "id": "2v2D1coL7I8i"
      },
      "source": [
        "<h1><center>Laboratorio 6: La solicitud de Sergio ü§ó</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2024</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d3d6f6d405c54dbe985a5f4b3e4f9120",
        "deepnote_cell_type": "markdown",
        "id": "YxdTmIPD7L_x"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti√°n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicol√°s Ojeda, Melanie Pe√±a, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "851a7788e8214942863cbd4099064ab2",
        "deepnote_cell_type": "markdown",
        "id": "Y2Gyrj-x7N2L"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Diego Bartolucci\n",
        "- Nombre de alumno 2: Pilar Nilo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f23a189afdec4e198683308db70e43b7",
        "deepnote_cell_type": "markdown",
        "id": "jQ9skYc57Pxi"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [ Repositorio](https://github.com/DiegoBarto01/MDS7202-pili-barto.git)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5318f41cda64d4290a7a548956ed725",
        "deepnote_cell_type": "markdown",
        "id": "1M4PoEWm7S80"
      },
      "source": [
        "## Temas a tratar\n",
        "- Aplicar Pandas para obtener caracter√≠sticas de un DataFrame.\n",
        "- Aplicar Pipelines y Column Transformers.\n",
        "- Utilizar diferentes algoritmos de cluster y ver el desempe√±o.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C√≥digo que no se pueda ejecutar, no ser√° revisado.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c√≥mo aplicar pipelines de Scikit-Learn para generar clusters.\n",
        "- Familiarizarse con plotly.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `numpy`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre arreglos (*o tensores*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "858df483d9e64780a21674afed1d34b8",
        "deepnote_cell_type": "markdown",
        "id": "SuMbiyQZG2Cc"
      },
      "source": [
        "## Descripci√≥n del laboratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "403ffe48ec994afda4b91e670a08d0ef",
        "deepnote_cell_type": "markdown",
        "id": "QZsNO4rUrqCz"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/5a/a6/af/5aa6afde8490da403a21601adf7a7240.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0303baa17d4546feae8c9b88c58470bf",
        "deepnote_cell_type": "markdown",
        "id": "2o0MPuk8rqCz"
      },
      "source": [
        "En el coraz√≥n de las operaciones de Aerol√≠nea Lucero, Sergio, el gerente de an√°lisis de datos, reuni√≥ a un talentoso equipo de j√≥venes cient√≠ficos de datos para un desaf√≠o crucial: segmentar la base de datos de los clientes. ‚ÄúNuestro objetivo es descubrir patrones en el comportamiento de los pasajeros que nos permitan personalizar servicios y optimizar nuestras campa√±as de marketing,‚Äù explic√≥ Sergio, mientras desplegaba un amplio rango de datos que inclu√≠an desde h√°bitos de compra hasta opiniones sobre los vuelos.\n",
        "\n",
        "Sergio encarg√≥ a los cient√≠ficos de datos la tarea de aplicar t√©cnicas avanzadas de clustering para identificar distintos segmentos de clientes, como los viajeros frecuentes y aquellos que eligen la aerol√≠nea para celebrar ocasiones especiales. La meta principal era entender profundamente c√≥mo estos grupos perciben la calidad y satisfacci√≥n de los servicios ofrecidos por la aerol√≠nea.\n",
        "\n",
        "A trav√©s de un enfoque meticuloso y colaborativo, los cient√≠ficos de datos se abocaron a la tarea, buscando transformar los datos brutos en valiosos insights que permitir√≠an a Aerol√≠nea Lucero no solo mejorar su servicio, sino tambi√©n fortalecer las relaciones con sus clientes mediante una oferta m√°s personalizada y efectiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e78cb41b144041af98928ab26dcfdaa9",
        "deepnote_cell_type": "markdown",
        "id": "hs4KKWF1Hdpo"
      },
      "source": [
        "## Importamos librerias utiles üò∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "95a5533cfd6d49cfb9afc111c44d224f",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 15,
        "execution_start": 1714107106552,
        "id": "a4YpMafirqC0",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmB0hlRThpT8",
        "outputId": "0aa96934-7f55-45eb-cabf-8b4d63a71e52"
      },
      "outputs": [],
      "source": [
        "# Si usted est√° utilizando Colabolatory le puede ser √∫til este c√≥digo para cargar los archivos.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    path = '/content/drive/MyDrive/Lab_6/'\n",
        "except:\n",
        "    print('Ignorando conexi√≥n drive-colab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "acbeab32db6146678e75448dddf43da8",
        "deepnote_cell_type": "markdown",
        "id": "UQOXod4gHhSq"
      },
      "source": [
        "## 1. Estudio de Performance üìà [10 Puntos]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "704b56b978254ad3ae12cdbf58f4832d",
        "deepnote_cell_type": "markdown",
        "id": "Gn5u5ICkrqC2"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://user-images.githubusercontent.com/57133330/188281408-c67df9ee-fd1f-4b37-833b-f02848f1ce02.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d35fbdcc5ef045d6a2822622f0714179",
        "deepnote_cell_type": "markdown",
        "id": "y4Z0jTjtrqC2"
      },
      "source": [
        "Don Sergio les ha encomendado su primera tarea: analizar diversas t√©cnicas de clustering. Su objetivo es entender detalladamente c√≥mo funcionan estos m√©todos en t√©rminos de segmentaci√≥n y eficiencia en tiempo de ejecuci√≥n.\n",
        "\n",
        "Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering (k-means, DBSCAN, Ward y GMM) aplicados a tres conjuntos de datos, incrementando progresivamente su tama√±o. Utilice Plotly para las gr√°ficas y discuta los resultados tanto cualitativa como cuantitativamente.\n",
        "\n",
        "Uno de los requisitos establecidos por Sergio es que el an√°lisis se lleve a cabo utilizando Plotly; de no ser as√≠, se considerar√° incorrecto. Para facilitar este proceso, se ha proporcionado un c√≥digo de Plotly que puede servir como base para realizar las gr√°ficas. Ap√≥yese en el c√≥digo entregado para efectuar el an√°lisis y tome como referencia la siguiente imagen para realizar los gr√°ficos:\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-04-26_at_9.10.44_AM.png' width=800 />\n",
        "\n",
        "En el gr√°fico se visualizan en dos dimensiones los diferentes tipos de datos proporcionados en `datasets`. Cada columna corresponde a un modelo de clustering diferente, mientras que cada fila representa un conjunto de datos distinto. Cada uno de los gr√°ficos incluye el tiempo en segundos que tarda el an√°lisis y la m√©trica Silhouette obtenida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "37580aab6cef4238a8ce42c50a6d35de",
        "deepnote_cell_type": "markdown",
        "id": "maCUNAvZrqC2"
      },
      "source": [
        "Para ser m√°s espec√≠ficos, usted debe cumplir los siguientes objetivos:\n",
        "1. Generar una funci√≥n que permita replicar el gr√°fico expuesto en la imagen (no importa que los colores calcen). [4 puntos]\n",
        "2. Ejecuta la funci√≥n para un `n_samples` igual a 1000, 5000, 10000. [2 puntos]\n",
        "3. Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering utilizando las 3 configuraciones dadas en `n_samples`. [4 puntos]\n",
        "\n",
        "\n",
        "> ‚ùó Tiene libertad absoluta de escoger los hiper par√°metros de los cluster, sin embargo, se recomienda verificar el dominio de las variables para realizar la segmentaci√≥n.\n",
        "\n",
        "> ‚ùó Recuerde que es obligatorio el uso de plotly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "7f7c25e366754595b13fc2e8116f65a0",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 78,
        "execution_start": 1714107108441,
        "id": "i0IZPGPOrqC3",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "En la siguiente celda se crean los datos ficticios a usar en la secci√≥n 1 del lab.\n",
        "‚ùóNo realice cambios a esta celda a excepci√≥n de n_samples‚ùó\n",
        "\"\"\"\n",
        "\n",
        "# Datos a utilizar\n",
        "\n",
        "# Configuracion\n",
        "n_samples = 5000 #Este par√°metro si lo pueden modificar\n",
        "\n",
        "def create_data(n_samples):\n",
        "\n",
        "    # Lunas\n",
        "    moons = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=30)\n",
        "    # Blobs\n",
        "    blobs = datasets.make_blobs(n_samples=n_samples, random_state=172)\n",
        "    # Datos desiguales\n",
        "    transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
        "    mutated = (np.dot(blobs[0], transformation), blobs[1])\n",
        "\n",
        "    # Generamos Dataset\n",
        "    dataset = {\n",
        "        'moons':{\n",
        "            'x': moons[0], 'classes': moons[1], 'n_cluster': 2\n",
        "        },\n",
        "        'blobs':{\n",
        "            'x': blobs[0], 'classes': blobs[1], 'n_cluster': 3\n",
        "        },\n",
        "        'mutated':{\n",
        "            'x': mutated[0], 'classes': mutated[1], 'n_cluster': 3\n",
        "        }\n",
        "    }\n",
        "    return dataset\n",
        "\n",
        "data_sets = create_data(n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y51s6f_UtIkc"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "643d6b35af5541358f481fda4d3fc51f",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 267,
        "execution_start": 1714108733824,
        "id": "CO3JFqezrqC3",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "def plot_scatter(x, y, color):\n",
        "    #Escriba su c√≥digo aqu√≠\n",
        "    fig = go.Figure(data=[go.Scatter(\n",
        "            x=x,\n",
        "            y=y,\n",
        "            mode='markers',\n",
        "            marker=dict(size=8, color=color, showscale=False)\n",
        "            )])\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBwyrPlaQCtR",
        "outputId": "88205f55-51ad-4da5-c587-adc494050f32"
      },
      "outputs": [],
      "source": [
        "data_sets['moons']['x'][:,0]\n",
        "data_sets['moons']['x'][:,1]\n",
        "data_sets['moons']['x']\n",
        "data_sets['moons']['classes']\n",
        "data_sets['blobs']['x']\n",
        "data_sets['blobs']['classes']\n",
        "data_sets['mutated']['x']\n",
        "data_sets['mutated']['classes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_xm4VZFRVka"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans , DBSCAN , AgglomerativeClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from time import time\n",
        "from sklearn.metrics import silhouette_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDFiSrdJs_Sm"
      },
      "outputs": [],
      "source": [
        "def plot_data(n_samples):\n",
        "  #creo el dataset\n",
        "  data_sets = create_data(n_samples)\n",
        "  #creo la estructura del plot\n",
        "  fig = make_subplots(rows=3, cols=4, subplot_titles=('Kmeans','GMM','WARD','DBSCAN')*3)\n",
        "  #relleno el plot\n",
        "  i=0\n",
        "  for data in data_sets:\n",
        "    #print(data)\n",
        "    clases=data_sets[data]['classes']\n",
        "    clusters=data_sets[data]['n_cluster']\n",
        "    #----K MEANS---\n",
        "    t0_kmeans=time()\n",
        "    kmeans_sil=silhouette_score(data_sets[data]['x'],clases)\n",
        "    k_means = KMeans(n_clusters=clusters).fit(data_sets[data]['x'])\n",
        "    t1_kmeans=time()\n",
        "\n",
        "    #----DBSCAN---\n",
        "    t0_dbscan=time()\n",
        "    dbscan_sil=silhouette_score(data_sets[data]['x'],clases)\n",
        "    dbscan = DBSCAN(eps=0.18, min_samples=100).fit(data_sets[data]['x'])\n",
        "    t1_dbscan=time()\n",
        "\n",
        "    #----WARD---\n",
        "    t0_ward=time()\n",
        "    ward_sil=silhouette_score(data_sets[data]['x'],clases)\n",
        "    ward = AgglomerativeClustering(n_clusters=clusters,linkage='ward').fit(data_sets[data]['x'])\n",
        "    t1_ward=time()\n",
        "\n",
        "    #----GMM---\n",
        "    t0_gmm=time()\n",
        "    gmm_sil=silhouette_score(data_sets[data]['x'],clases)\n",
        "    gmm = GaussianMixture(n_components=clusters).fit(data_sets[data]['x'])\n",
        "    t1_gmm=time()\n",
        "\n",
        "    #Diferencias de tiempo\n",
        "    kmeans_time=t1_kmeans-t0_kmeans\n",
        "    dbscan_time=t1_dbscan-t0_dbscan\n",
        "    ward_time=t1_ward-t0_ward\n",
        "    gmm_time=t1_gmm-t0_gmm\n",
        "\n",
        "    #clases o labels\n",
        "    k_means_labels = k_means.labels_\n",
        "    dbscan_labels = dbscan.labels_\n",
        "    ward_labels = ward.labels_\n",
        "    gmm_labels = gmm.predict(data_sets[data]['x'])\n",
        "\n",
        "    #lo que va en cada subplot\n",
        "    fig.add_trace(plot_scatter(data_sets[data]['x'][:,0], data_sets[data]['x'][:,1], k_means_labels).data[0], row=i+1, col=1)\n",
        "    fig.add_trace(plot_scatter(data_sets[data]['x'][:,0], data_sets[data]['x'][:,1], gmm_labels).data[0], row=i+1, col=2)\n",
        "    fig.add_trace(plot_scatter(data_sets[data]['x'][:,0], data_sets[data]['x'][:,1], ward_labels).data[0], row=i+1, col=3)\n",
        "    fig.add_trace(plot_scatter(data_sets[data]['x'][:,0], data_sets[data]['x'][:,1], dbscan_labels).data[0], row=i+1, col=4)\n",
        "\n",
        "    #titulos para cada subplot con el tiempo y silhouette\n",
        "    fig.layout.annotations[i*4 + 0].text = f'Sil: {kmeans_sil:.2f}\\nt: {kmeans_time:.2f} s'\n",
        "    fig.layout.annotations[i*4 + 1].text = f'Sil: {gmm_sil:.2f}\\nt: {gmm_time:.2f} s'\n",
        "    fig.layout.annotations[i*4 + 2].text = f'Sil: {ward_sil:.2f}\\nt: {ward_time:.2f} s'\n",
        "    fig.layout.annotations[i*4 + 3].text = f'Sil: {dbscan_sil:.2f}\\nt: {dbscan_time:.2f} s'\n",
        "\n",
        "\n",
        "    i+=1\n",
        "  #agrego titulo\n",
        "  fig.update_layout(height=1000, width=1000,title_text='Comparaci√≥n de M√©todos de Clustering',showlegend=False)\n",
        "  #muestro el plot\n",
        "  fig.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AOJ6bkLlaQ1U",
        "outputId": "f4d3ce02-c2a8-4435-f044-8ade20fa3bd0"
      },
      "outputs": [],
      "source": [
        "plot_data(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dMc7076kaOV1",
        "outputId": "49722a1d-b3d5-4a41-9b59-3583bc0c960e"
      },
      "outputs": [],
      "source": [
        "plot_data(5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N7Linm0FaUoz",
        "outputId": "f4ea0ed5-f63e-4e31-f155-5aff31343031"
      },
      "outputs": [],
      "source": [
        "plot_data(10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaiU0w8JyYbO"
      },
      "source": [
        "*Analisis y comparaci√≥n*\n",
        "\n",
        "\n",
        "Visualizando los gr√°ficos de los algoritmos de clustering se puede notar que a medida que el numero de samples aumenta, el tiempo de ejecuci√≥n tambien lo hace, esto se debe a que hace m√°s iteraciones.\n",
        "\n",
        "Tambien es importante destacar que el dataset 'blobs' es el que presenta mejor m√©trica silhouette (0.78) respecto a los otros que son bastante bajos indicando que no se realiza un buen agrupamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "13c5cb8067d9415f83b3d497954a437a",
        "deepnote_cell_type": "markdown",
        "id": "3mCbZc86rqC6"
      },
      "source": [
        "## 2. An√°lisis de Satisfacci√≥n de Vuelos. [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd6e991646b44f50a4b13f01d1542415",
        "deepnote_cell_type": "markdown",
        "id": "JI33m5jbrqC6"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.gifer.com/2Hci.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5742dfbd5a2e43778ff250436bab1005",
        "deepnote_cell_type": "markdown",
        "id": "h5k24znirqC7"
      },
      "source": [
        "Habiendo entendido c√≥mo funcionan los modelos de aprendizaje no supervisado, *Don Sergio* le encomienda estudiar la satisfacci√≥n de pasajeros al haber tomado un vuelo en alguna de sus aerolineas. Para esto, el magnate le dispone del dataset `aerolineas_licer.parquet`, el cual contiene el grado de satisfacci√≥n de los clientes frente a diferentes aspectos del vuelo. Las caracter√≠sticas del vuelo se definen a continuaci√≥n:\n",
        "\n",
        "- *Gender*: G√©nero de los pasajeros (Femenino, Masculino)\n",
        "- *Customer Type*: Tipo de cliente (Cliente habitual, cliente no habitual)\n",
        "- *Age*: Edad actual de los pasajeros\n",
        "- *Type of Travel*: Prop√≥sito del vuelo de los pasajeros (Viaje personal, Viaje de negocios)\n",
        "- *Class*: Clase de viaje en el avi√≥n de los pasajeros (Business, Eco, Eco Plus)\n",
        "- *Flight distance*: Distancia del vuelo de este viaje\n",
        "- *Inflight wifi service*: Nivel de satisfacci√≥n del servicio de wifi durante el vuelo (0:No Aplicable; 1-5)\n",
        "- *Departure/Arrival time convenient*: Nivel de satisfacci√≥n con la conveniencia del horario de salida/llegada\n",
        "- *Ease of Online booking*: Nivel de satisfacci√≥n con la facilidad de reserva en l√≠nea\n",
        "- *Gate location*: Nivel de satisfacci√≥n con la ubicaci√≥n de la puerta\n",
        "- *Food and drink*: Nivel de satisfacci√≥n con la comida y la bebida\n",
        "- *Online boarding*: Nivel de satisfacci√≥n con el embarque en l√≠nea\n",
        "- *Seat comfort*: Nivel de satisfacci√≥n con la comodidad del asiento\n",
        "- *Inflight entertainment*: Nivel de satisfacci√≥n con el entretenimiento durante el vuelo\n",
        "- *On-board service*: Nivel de satisfacci√≥n con el servicio a bordo\n",
        "- *Leg room service*: Nivel de satisfacci√≥n con el espacio para las piernas\n",
        "- *Baggage handling*: Nivel de satisfacci√≥n con el manejo del equipaje\n",
        "- *Check-in service*: Nivel de satisfacci√≥n con el servicio de check-in\n",
        "- *Inflight service*: Nivel de satisfacci√≥n con el servicio durante el vuelo\n",
        "- *Cleanliness*: Nivel de satisfacci√≥n con la limpieza\n",
        "- *Departure Delay in Minutes*: Minutos de retraso en la salida\n",
        "- *Arrival Delay in Minutes*: Minutos de retraso en la llegada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOoIFHpw5xCW"
      },
      "source": [
        "En consideraci√≥n de lo anterior, realice las siguientes tareas:\n",
        "\n",
        "0. Ingeste el dataset a su ambiente de trabajo.\n",
        "\n",
        "1. Seleccione **s√≥lo las variables num√©ricas del dataset**.  Explique qu√© √©fectos podr√≠a causar el uso de variables categ√≥ricas en un algoritmo no supervisado. [2 punto]\n",
        "\n",
        "2. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones. [2 punto]\n",
        "\n",
        "3. Bas√°ndose en los gr√°ficos, eval√∫e la necesidad de escalar los datos y explique el motivo de su decisi√≥n. [2 puntos]\n",
        "\n",
        "4. Examine la correlaci√≥n entre las variables mediante un correlograma. [2 puntos]\n",
        "\n",
        "5. De acuerdo con los resultados obtenidos en 5, reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO6tcVBCtxxS"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ioaeblx-FZ4"
      },
      "source": [
        "*1. efecto de usar variables categoricas en algoritmo no supervisado*\n",
        "\n",
        "El efecto de usar variables categoricas es que est√°s indican cualidades y en caso de que se asocien con n√∫meros, estos no permiten aplicar operaciones sobre ellos, es decir, calcular m√©tricas para un analisis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpXFyjOWaw7A"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pzHTZ17xveU_",
        "outputId": "2759af87-814a-41f7-817a-e8865c449ebb"
      },
      "outputs": [],
      "source": [
        "# 0.Carga de datos\n",
        "# /content/drive/MyDrive/Lab_6/aerolineas_lucer.parquet\n",
        "df_vuelos= pd.read_parquet(path + 'aerolineas_lucer.parquet')\n",
        "\n",
        "#1.seleccion de variables numricas del dataset\n",
        "df_vuelos_num= df_vuelos.select_dtypes(include='number')\n",
        "#suponemos que el ID no es una columna a contabilizar\n",
        "df_vuelos_num= df_vuelos_num.drop('id', axis=1)\n",
        "\n",
        "#2.visualizaci√≥n de la distribuci√≥n de cada variable\n",
        "for col in df_vuelos_num.columns:\n",
        "    fig = px.histogram(df_vuelos_num, x=col, title=f'Visualizaci√≥n de la distribuci√≥n de variable {col}') #ver si es solo histo o podria ser otro\n",
        "    fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0PrElK8_bXh"
      },
      "source": [
        "*2.analisis de cada una de las distribuciones*\n",
        "\n",
        "\n",
        "\n",
        "*   Age: La concentraci√≥n de edades se encuentra entre los 20 y 60 a√±os\n",
        "*   Flight Distance: Se visualiza que mayoritariamente se vuelan distancias cortas o no superiores a 1000. Distancias mayores a la anterior son de poca frecuencia.\n",
        "* Inflight wifi service: Entre 2 a 3 poseen servicio de wifi en los aviones\n",
        "* Departure/Arrival time convenient: los vuelos presentan inconvenientes en la llegada o partida en su gran mayoria.\n",
        "* Ease of Online booking: representa que la mayoria de las veces es f√°cil hacer una reserva online\n",
        "* Gate location: hay con mayor frecuencia 3 gates location\n",
        "* Food and drink: La mayor√≠a de los vuelos tienen food/drink\n",
        "* Online boarding: la mayoria de los vuelos posee online boarding\n",
        "* Seat comfort: se presenta con mayor frecuencia vuelos con asientos comodos\n",
        "* Inflight entertainment: se presenta con mayor frecuencia vuelos con entretenimiento durante el vuelo\n",
        "* On-board service: se presenta con mayor frecuencia vuelos con onboard services\n",
        "* Leg room service: se presenta con mayor frecuencia vuelos con leg room service\n",
        "* Baggage handling: se presenta con mayor frecuencia vuelos con baggage handling\n",
        "* Chekin service:se presenta con mayor frecuencia vuelos con chekin service\n",
        "* Inflight service: se presenta con mayor frecuencia vuelos con inflight service\n",
        "* Cleanliness: se presenta con mayor frecuencia vuelos cleanliness\n",
        "* Departure delay in minutes: No se alcanza a visualizar la mayor frecuencia en minutos de departure delay, pero a priori ser√≠a menos de 50 minutos.\n",
        "* Arrive delay in minutes: Al igual que departure no se visualiza de buena manera, pero a priori ser√≠an menos de 50 minutos.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdlbH6z8B3FN"
      },
      "source": [
        "*3. evaluaci√≥n y explicacion de escalar datos*\n",
        "\n",
        "Se decide escalar los datos dado que las √∫ltimas dos variables no son capaces de visualizarse de mejor manera, adem√°s cabe la posibilidad de mejorar la vista de los datos de las otras variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S_HMEk8q_VoE",
        "outputId": "83b5e2ae-2abd-4859-d678-61baa9ab3875"
      },
      "outputs": [],
      "source": [
        "#3.eval√∫e la necesidad de escalar los datos\n",
        "scaler = MinMaxScaler()\n",
        "df_scale = scaler.fit_transform(df_vuelos_num)\n",
        "df_scale = pd.DataFrame(df_scale, columns=df_vuelos_num.columns)\n",
        "for col in df_scale.columns:\n",
        "    fig = px.histogram(df_scale, x=col, title=f'Visualizaci√≥n de la distribuci√≥n de variable {col} escalado con MinMaxScaler')\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "hcOobFX5B0nj",
        "outputId": "6f795e2d-382a-43c5-bb27-8288d63c16d2"
      },
      "outputs": [],
      "source": [
        "#4.examine la correlaci√≥n entre las variables mediante un correlograma\n",
        "correlacion= df_scale.corr()\n",
        "fig = px.imshow(correlacion,\n",
        "                title='Correlograma',\n",
        "                aspect=\"16:9\",\n",
        "                height=800,\n",
        "                zmin=-1,\n",
        "                color_continuous_midpoint=0,\n",
        "                zmax=1,\n",
        "                color_continuous_scale=px.colors.sequential.Viridis)\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHRRhxy6C3b8"
      },
      "source": [
        "*4.correlaci√≥n*\n",
        "\n",
        "Se puede ver una matriz de correlaci√≥n donde hay pocas variables de alta correlaci√≥n, por lo cual nos puede dar indicio de que al realizar alg√∫n modelo de evaluaci√≥n o algo similar, habr√≠a que quitar bastantes variables para que sea representativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4LaRj6MC3Dl",
        "outputId": "785a77b6-3389-447c-f430-e42d067b1cde"
      },
      "outputs": [],
      "source": [
        "#5.reduzca la dimensionalidad del conjunto de datos a cuatro variables\n",
        "diagonal = correlacion.where(~np.eye(correlacion.shape[0], dtype=bool))\n",
        "high_corr = diagonal.stack().sort_values(ascending=False)\n",
        "print(high_corr.head(12))\n",
        "df_reducido= df_scale[['Arrival Delay in Minutes', 'Online boarding', 'Flight Distance', 'Inflight wifi service']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrba5FCsDqS1"
      },
      "source": [
        "*5.variables que se quitaron*\n",
        "\n",
        "Dado que se piden dejar 4 variables, se dejan las variables con mayor correlaci√≥n, es decir, 'Arrival Delay in Minutes', 'Online boarding', 'Flight distance' y 'Inflight wifi service'. Las cuales poseen una correlaci√≥n mayor a 0.6, exceptuando Online Boarding, pero esta se decide incluir como variable intermedia ya que nos indicar√≠a alguna relaci√≥n interesante con las otras al ser el boleto que permite subirse al avi√≥n.\n",
        "\n",
        "Si lo pensamos de manera que estas variables tengan un impacto en alg√∫n modelo, se puede perfectamente relacionar el atraso de salida con la llegada tardia de un vuelo, asi como tambien la duraci√≥n de vuelo con el hecho de que exista wifi o no en el avi√≥n, ya que entre m√°s largo el vuelo, m√°s entretenci√≥n va a necesitar la gente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "4b6c047d994f40ea9e78a36a777042e0",
        "deepnote_cell_type": "markdown",
        "id": "PNGfTgtkrqC9"
      },
      "source": [
        "## 3. Preprocesamiento üé≠. [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "713b3f0e61dd4841bb5b38c730d344d5",
        "deepnote_cell_type": "markdown",
        "id": "6RZD0fMNrqC-"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/1e/a8/0e/1ea80e7cea0d429146580c7e91c5b944.gif\" width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "98400c7b5fec4af193eec3601f53891e",
        "deepnote_cell_type": "markdown",
        "id": "J6d4VEOTrqC-"
      },
      "source": [
        "Tras quedar satisfecho con los resultados presentados en el punto 2, el due√±o de la empresa ha solicitado que se preprocesen los datos mediante un `pipeline`. Es crucial que este proceso tenga en cuenta las observaciones derivadas de los an√°lisis anteriores. Adicionalmente, ha expresado su inter√©s en visualizar el conjunto de datos en un gr√°fico de dos o tres dimensiones.\n",
        "\n",
        "Bas√°ndose en los an√°lisis realizados anteriormente:\n",
        "1. Cree un `pipeline` que incluya PCA, utilizando las consideraciones mencionadas previamente para proyectar los datos a dos dimensiones. [4 puntos]\n",
        "2. Grafique los resultados obtenidos y comente lo visualizado. [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paDSaGoq0OUp"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "ad1e70818ad748638ca0927b07a76125",
        "deepnote_cell_type": "code",
        "id": "gBYG238wrqC-"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "#Se crea el pipeline que tenga PCA\n",
        "pipeline = Pipeline([\n",
        "    #Se decidi√≥ usar standardscaler especificamente para esta secci√≥n para ver una representacion de los datos que se pudiera interpretar de una manera m√°s sencilla.\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA(n_components=2))\n",
        "])\n",
        "\n",
        "df_transformed = pipeline.fit_transform(df_reducido)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "72_WsSVFkKeu",
        "outputId": "ae6f7fd1-19f0-4d19-e2c8-4a64091b8669"
      },
      "outputs": [],
      "source": [
        "#Se grafican los resultados\n",
        "fig = px.scatter(x = df_transformed[:, 0],\n",
        "                 y = df_transformed[:, 1],\n",
        "                 labels={'x' : \"Principal Component 1\",\n",
        "                         'y' : \"Principal Component 2\"},\n",
        "                 title = 'Scatter Plot 2D PCA')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA7InqPfkPM5"
      },
      "source": [
        "Como se puede observar en el gr√°fico, los datos elegidos, al tener una correlaci√≥n moderada entre ellos, se concentran los valores en PC2 = 0 teniendo casos particulares que sobresalen. En PC1 se distribuyen en todo su espectro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bd281470d3054764a63d857cfa7d52a6",
        "deepnote_cell_type": "text-cell-h2",
        "formattedRanges": [],
        "id": "7ENoOtIIrqC_"
      },
      "source": [
        "## 4. Outliers üö´üôÖ‚Äç‚ôÄÔ∏è‚ùåüôÖ‚Äç‚ôÇÔ∏è [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "db89e9c9f35c44abbd8991180226c0ea",
        "deepnote_cell_type": "markdown",
        "id": "fbGw6Sa-rqC_"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://joachim-gassen.github.io/images/ani_sim_bad_leverage.gif\" width=250>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3e2f59fa12954641af7a854a4e203694",
        "deepnote_cell_type": "markdown",
        "id": "nl_ccu9brqDA"
      },
      "source": [
        "Con el objetivo de mantener la claridad en su an√°lisis, Don Sergio le ha solicitado entrenar un modelo que identifique pasajeros con comportamientos altamente at√≠picos.\n",
        "\n",
        "1. Utilice `IsolationForest` para clasificar las anomal√≠as del dataset (sin aplicar PCA), configurando el modelo para que s√≥lo el 1% de los datos sean considerados an√≥malos. Aseg√∫rese de integrar esta tarea dentro de un `pipeline`. [3 puntos]\n",
        "\n",
        "2. Visualice los resultados en el gr√°fico de dos dimensiones previamente creado. [3 puntos]\n",
        "\n",
        "3. ¬øC√≥mo evaluar√≠a el rendimiento de su modelo en la detecci√≥n de anomal√≠as? [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5cS1FR00NlF"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "be86896911244aa89e3b5f3f00a286af",
        "deepnote_cell_type": "code",
        "id": "iaPZFmjyrqDA"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "#Ya que se pide 1% de los datos anomalos se considera una contaminaci√≥n del 1%, es decir, de 0,01.\n",
        "isolation_forest_model = IsolationForest(contamination=0.01)\n",
        "\n",
        "#Despu√©s se crea un nuevo pipeline sin PCA\n",
        "pipeline_anomalias = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('isolation_forest', isolation_forest_model)\n",
        "])\n",
        "\n",
        "pipeline_anomalias.fit(df_reducido)\n",
        "\n",
        "anomalias_prediction = pipeline_anomalias.predict(df_reducido)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_1S_byGTpFX"
      },
      "outputs": [],
      "source": [
        "df_reducido_anomalias = pd.DataFrame(np.column_stack((df_transformed, anomalias_prediction)))\n",
        "df_reducido_anomalias[2] = df_reducido_anomalias[2].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "f8sLbJX6TyIN",
        "outputId": "5ca0c195-ad8d-41ed-8443-0b4f11e5d7ed"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(x = df_reducido_anomalias [0],\n",
        "                 y = df_reducido_anomalias [1],\n",
        "                 labels={'x' : \"Principal Component 1\",\n",
        "                         'y' : \"Principal Component 2\"},\n",
        "                 color=df_reducido_anomalias[2],\n",
        "                 title = 'Scatter Plot 2D PCA',\n",
        "                 color_discrete_map={1: 'blue', -1: 'red'})\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2k0lVAokhXq"
      },
      "source": [
        "Se puede observar que se consideran como anomal√≠as aquellos valores que tienen un valor alto del PC2, es decir, los valores que se alejan del gran conjunto de datos presentes cerca del valor PC2=0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3871e2fe5bdd422dbdbfaebf75503ae3",
        "deepnote_cell_type": "markdown",
        "id": "zQFTklmVrqDB"
      },
      "source": [
        "## 5. M√©tricas de Desempe√±o üöÄ [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "236333de6dd445c182aefcc507589325",
        "deepnote_cell_type": "markdown",
        "id": "YpNj4wbPrqDB"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://giffiles.alphacoders.com/219/219081.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a7e1ceb91be94b1da2ab8be97dfac999",
        "deepnote_cell_type": "markdown",
        "id": "CR3hzRxrrqDB"
      },
      "source": [
        "Motivado por incrementar su fortuna, Don Sergio le solicita entrenar un modelo que le permita segmentar a los pasajeros en grupos distintos, con el objetivo de optimizar las diversas campa√±as de marketing dise√±adas por su equipo. Para ello, le se pide realizar las siguientes tareas:\n",
        "\n",
        "1. Utilizar el modelo **Gaussian Mixture** y explore diferentes configuraciones de n√∫mero de cl√∫sters, espec√≠ficamente entre 3 y 8. Aseg√∫rese de integrar esta operaci√≥n dentro de un `pipeline`. [4 puntos]\n",
        "2. Explique cu√°l ser√≠a el criterio adecuado para seleccionar el n√∫mero √≥ptimo de cl√∫sters. **Justifique de forma estadistica y a traves de gr√°ficos.** [6 puntos]\n",
        "\n",
        "> **HINT:** Se recomienda investigar sobre los criterios AIC y BIC para esta tarea."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_T_zTg0MXB"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "6d3d1bb3fda14321984466d9101a775a",
        "deepnote_cell_type": "code",
        "id": "5GeUb9J3rqDB"
      },
      "outputs": [],
      "source": [
        "#1. utilizar modelo gaussian mixture explorar dif conf de n_cluster (3 a 8), esto dentro de un pipeline\n",
        "from sklearn.mixture import GaussianMixture\n",
        "valores_AIC=[]\n",
        "valores_BIC=[]\n",
        "cluster = []\n",
        "for n_clusters in range(3, 9):\n",
        "    pipeline_gmm = Pipeline([\n",
        "        ('scaler', MinMaxScaler()),\n",
        "        ('gmm', GaussianMixture(n_components=n_clusters, random_state=0))\n",
        "    ])\n",
        "    pipeline_gmm.fit(df_reducido_anomalias)\n",
        "\n",
        "    gmm_model = pipeline_gmm['gmm']\n",
        "    #escalo el df_reducido\n",
        "    df_reducido_scaled = pipeline_gmm['scaler'].transform(df_reducido_anomalias)\n",
        "    gmm_predict= gmm_model.predict(df_reducido_anomalias)\n",
        "    cluster.append(gmm_predict)\n",
        "    #calcular AIC y BIC\n",
        "    valores_AIC.append(gmm_model.aic(df_reducido_scaled))\n",
        "    valores_BIC.append(gmm_model.bic(df_reducido_scaled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rjA9krSrASj",
        "outputId": "c07d3d07-2533-40ae-c884-a57e89a09bf1"
      },
      "outputs": [],
      "source": [
        "valores_AIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IyQxqJQrH6r",
        "outputId": "03605cc1-76f2-4391-81f0-3b6a0717035b"
      },
      "outputs": [],
      "source": [
        "valores_BIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fdeXBpyxrKVF",
        "outputId": "781fd1b1-9450-4c3e-d3f0-8126dd8be9d3"
      },
      "outputs": [],
      "source": [
        "#Definir los datos\n",
        "n_clusters = list(range(3, 9))\n",
        "\n",
        "#Crear un DataFrame con los datos\n",
        "data_A = {\n",
        "    'n_clusters': n_clusters,\n",
        "    'valor': valores_AIC,\n",
        "    'metrica': ['AIC'] * len(n_clusters)}\n",
        "\n",
        "data_A = pd.DataFrame(data_A)\n",
        "\n",
        "data_B = {\n",
        "    'n_clusters': n_clusters,\n",
        "    'valor': valores_BIC,\n",
        "    'metrica': ['BIC'] * len(n_clusters)}\n",
        "\n",
        "#Crear el DataFrame\n",
        "data_B = pd.DataFrame(data_B)\n",
        "\n",
        "#Ploteamos\n",
        "fig_A= px.line(\n",
        "    x=data_A['n_clusters'],\n",
        "    y=data_A['valor'],\n",
        "    color=data_A['metrica'],\n",
        "    labels={'x': '# de clusters', 'y': 'valor'},\n",
        "    title='Estad√≠sticas'\n",
        ")\n",
        "\n",
        "fig_A.show()\n",
        "\n",
        "fig_B= px.line(\n",
        "    x=data_B['n_clusters'],\n",
        "    y=data_B['valor'],\n",
        "    color=data_B['metrica'],\n",
        "    labels={'x': '# de clusters', 'y': 'valor'},\n",
        "    title='Estad√≠sticas'\n",
        ")\n",
        "\n",
        "fig_B.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FexzFhSEgH_"
      },
      "source": [
        "*explicacion del n_cluster*\n",
        "\n",
        "El numero de clusters optimo ser√≠a 5 ya que es cuando el gr√°fico, en ambos conjuntos de m√©trica (AIC y BIC), empieza a decaer. Lo anterior se basa en el m√©todo del codo ya que clusteres que est√°n despu√©s del punto de inflexi√≥n no minimizan la varianza dentro de los clusters de forma suficientemente significativa.\n",
        "\n",
        "Adem√°s es el cluster con m√°s 'codo' significativo ya que en los cluster 6 y 7 la pendiente no es t√°n abrupta como en el cluster 5.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "dd342e336254418ba766b29dce16b267",
        "deepnote_cell_type": "markdown",
        "id": "P9CERnaerqDC"
      },
      "source": [
        "## 6. An√°lisis de resultados üìä [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "953b5ad01a704b50b899db7176d1b7b2",
        "deepnote_cell_type": "markdown",
        "id": "I1yNa111rqDC"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.gifer.com/7wTk.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd90e2f135404353ac0b5ab844936ca7",
        "deepnote_cell_type": "markdown",
        "id": "dg0Qx4RZrqDC"
      },
      "source": [
        "Una vez identificado el n√∫mero √≥ptimo de cl√∫sters, se le pide realizar lo siguiente:\n",
        "\n",
        "1. Utilizar la proyecci√≥n en dos dimensiones para visualizar cada cl√∫ster claramente. [2 puntos]\n",
        "\n",
        "2. ¬øEs posible distinguir claramente entre los cl√∫sters generados? [2 puntos]\n",
        "\n",
        "3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos]\n",
        "\n",
        "4. Proceda a visualizar los cl√∫sters en tres dimensiones para una perspectiva m√°s detallada. [2 puntos]\n",
        "\n",
        "5. ¬øC√≥mo afecta esto a sus conclusiones anteriores? [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRN0zZip0IMB"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "zWOaFkAPG9g2",
        "outputId": "24460b2c-a911-4968-f934-c21d7ed51553"
      },
      "outputs": [],
      "source": [
        "#1. utilizar la proyeccion en dos dimensiones para visualizar cada cluster claramente\n",
        "#Primero hay que agregar una columna de Cluster a df_visualizacion para poder diferenciar los datos\n",
        "fig = px.scatter(x = df_reducido_anomalias[0],\n",
        "                 y = df_reducido_anomalias[1],\n",
        "                 labels={'x' : \"Principal Component 1\",\n",
        "                         'y' : \"Principal Component 2\"},\n",
        "                 color = cluster[2],\n",
        "                 title = 'Scatter Plot 2D PCA')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC1_JEFoHClQ"
      },
      "source": [
        "2.- Con la divisi√≥n de colores que proporciona plotly se puede observar como se dividen los cl√∫sters en el gr√°fico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHKCL3WOHDrR",
        "outputId": "c687998d-c6d7-4bc8-dfa7-68193fb8c825"
      },
      "outputs": [],
      "source": [
        "#3. estadisticas descriptivas basicas media y desviacion estandar\n",
        "df_reducido_anomalias['cluster'] = cluster[2]\n",
        "cluster_orden = df_reducido_anomalias['cluster'].unique()\n",
        "cluster_orden.sort()\n",
        "\n",
        "for i in cluster_orden:\n",
        "    df_clusters=df_reducido_anomalias[df_reducido_anomalias['cluster'] == i]\n",
        "\n",
        "    print(f'Media de cluster {i}: ')\n",
        "    print('Promedio PC1')\n",
        "    print(df_clusters[[0, 1]].mean()[0])\n",
        "    print('Promedio PC2')\n",
        "    print(df_clusters[[0, 1]].mean()[1])\n",
        "    print()\n",
        "    print(f'Std de cluster {i}: ')\n",
        "    print('Desviaci√≥n est√°ndar PC1')\n",
        "    print(df_clusters[[0, 1]].std()[0])\n",
        "    print('Desviaci√≥n est√°ndar PC2')\n",
        "    print(df_clusters[[0, 1]].std()[1])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep8PdXPeenU1"
      },
      "source": [
        "Observando los valores de promedio y desviaci√≥n est√°ndar por cl√∫ster conlcuimos:\n",
        "\n",
        "\n",
        "*   Cl√∫ster 0: Presenta un promedio alto para el primer componente (0.86) mientras que para el segundo presenta una media baja (0.06). Con respecto a su desviaci√≥n est√°ndar, es baja para ambos componentes, no superando 0.15 en ninguno de los dos.\n",
        "\n",
        "*   Cl√∫ster 1: Se presenta una media baja en ambos componentes de (-0.55) y de (0.04). Para la desviaci√≥n se observan una desviaci√≥n alta para el componente 1 de (1.49) y una desviaci√≥n baja para el componente 2  de (0.04).\n",
        "\n",
        "*   Cl√∫ster 2: Tiene un promedio bajo para el componente PC1 (-0.32) y alto para el componente PC2 (4.94). En desviaci√≥n se presentan desviaciones altas para ambos componentes de (1.46) y (2.82).\n",
        "\n",
        "*   Cl√∫ster 3: Hay promedios bajos para ambos componentes (-0.93) y (0.04). Se presentan desviaciones de (1.33) para PC1 y de (0.11) para PC2.\n",
        "\n",
        "*   Cl√∫ster 4: Los promedios de este cl√∫ster corresponden a (0.06) para PC1 y de (-0.06) para PC2. Las desviaciones est√°ndar corresponden a (1.19) para PC1 y (0.86) para PC2.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AR-g0FaBHI0a"
      },
      "outputs": [],
      "source": [
        "# Crear un nuevo pipeline para la reducci√≥n a 3 dimensiones\n",
        "pipeline_3d_pca = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('pca', PCA(n_components=3))\n",
        "])\n",
        "\n",
        "# Ajustar el pipeline a los datos\n",
        "pipeline_3d_pca.fit_transform(df_reducido)\n",
        "\n",
        "# Se agrega el isolation forest\n",
        "pipeline_3d_anomalias = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('isolation_forest', isolation_forest_model)\n",
        "])\n",
        "\n",
        "# Ajustar el pipeline a los datos\n",
        "pipeline_3d_anomalias.fit(df_reducido)\n",
        "anomalias_prediction_3d = pipeline_3d_anomalias.predict(df_reducido)\n",
        "\n",
        "# Se crea dataframe para modelo 3d\n",
        "df_reducido_anomalias_3d = pd.DataFrame(np.column_stack((pipeline_3d_pca.transform(df_reducido), anomalias_prediction_3d)))\n",
        "df_reducido_anomalias_3d[2] = df_reducido_anomalias_3d[2].astype('category')\n",
        "\n",
        "# Se hace la divisi√≥n de cl√∫sters\n",
        "gmm_3d = GaussianMixture(n_components = 5, random_state=0)\n",
        "gmm_3d.fit(df_reducido_anomalias_3d)\n",
        "gmm_labels = gmm_3d.predict(df_reducido_anomalias_3d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "y_IdLhbQidH5",
        "outputId": "d15b5156-1e14-48d2-c1ab-670510aff0bb"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter_3d(x = df_reducido_anomalias_3d[0],\n",
        "                    y = df_reducido_anomalias_3d[1],\n",
        "                    z = df_reducido_anomalias_3d[2],\n",
        "                    labels={'x' : \"Principal Component 1\",\n",
        "                            'y' : \"Principal Component 2\",\n",
        "                            'z' : \"Principal Component 3\"},\n",
        "                    color = gmm_labels,\n",
        "                    title = 'Scatter Plot 3D PCA')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGc7QOaRHLJX"
      },
      "source": [
        "5.- Se puede observar como los clusters se mezclan en el espacio, espec√≠ficamente los cl√∫sters 0, 1 y 2. El cl√∫ster 4 se presenta en la mayor cantidad a lo largo del volumen del \"cubo\" que se form√≥ con los datos. Generar un cl√∫ster con los cl√∫sters que comparten espacio puede producir una mayor armon√≠a en el espacio que se utiliza evitando estas superposiciones de datos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "7cb425aec99b4079954fd707109c42c3",
    "deepnote_persisted_session": {
      "createdAt": "2024-04-26T06:15:51.197Z"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
