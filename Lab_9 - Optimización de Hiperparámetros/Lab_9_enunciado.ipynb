{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5c0d2440b3e4995a794ded565213150",
        "deepnote_cell_type": "markdown",
        "id": "_Mql1uRoI5v5"
      },
      "source": [
        "<h1><center>Laboratorio 9: Optimizaci칩n de modelos 游눮</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos - Primavera 2024</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bfb94b9656f145ad83e81b75d218cb70",
        "deepnote_cell_type": "markdown",
        "id": "FAPGIlEAI5v8"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti치n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicol치s Ojeda, Melanie Pe침a, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b1b537fdd27c43909a49d3476ce64d91",
        "deepnote_cell_type": "markdown",
        "id": "8NozgbkZI5v9"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n",
        "\n",
        "- Nombre de alumno 1: Diego Bartolucci\n",
        "- Nombre de alumno 2: Pilar Nilo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stigeJyU5XdQ"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Repositorio](https://github.com/DiegoBarto01/MDS7202-pili-barto.git)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b7dbdd30ab544cb8a8afe00648a586ae",
        "deepnote_cell_type": "markdown",
        "id": "vHU9DI6wI5v9"
      },
      "source": [
        "### Temas a tratar\n",
        "\n",
        "- Predicci칩n de demanda usando `xgboost`\n",
        "- B칰squeda del modelo 칩ptimo de clasificaci칩n usando `optuna`\n",
        "- Uso de pipelines.\n",
        "\n",
        "### Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C칩digo que no se pueda ejecutar, no ser치 revisado.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Optimizar modelos usando `optuna`\n",
        "- Recurrir a t칠cnicas de *prunning*\n",
        "- Forzar el aprendizaje de relaciones entre variables mediante *constraints*\n",
        "- Fijar un pipeline con un modelo base que luego se ir치 optimizando.\n",
        "\n",
        "El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f1c73babb7f74af588a4fa6ae14829e0",
        "deepnote_cell_type": "markdown",
        "id": "U_-sNOuOI5v9"
      },
      "source": [
        "# Importamos librerias 칰tiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "51afe4d2df42442b9e5402ffece60ead",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 4957,
        "execution_start": 1699544354044,
        "id": "ekHbM85NI5v9",
        "outputId": "cfbebb3c-85e2-4371-8582-fdbbb90cecef",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "!pip install -qq xgboost optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6hJXpLCSspz"
      },
      "source": [
        "# El emprendimiento de Fiu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "44d227389a734ac59189c5e0005bc68a",
        "deepnote_cell_type": "markdown",
        "id": "b0bDalAOI5v-"
      },
      "source": [
        "Tras liderar de manera exitosa la implementaci칩n de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corp칩reo **Fiu** se anima y decide levantar su propio negocio de consultor칤a en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Al ver el gran potencial y talento que usted ha demostrado en el campo de la ciencia de datos, Fiu lo contrata como data scientist para que forme parte de su nuevo emprendimiento.\n",
        "\n",
        "Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n",
        "\n",
        "Para comenzar, cargue el dataset se침alado y visualice a trav칠s de un `.head` los atributos que posee el dataset.\n",
        "\n",
        "<i><p align=\"center\">Fiu siendo felicitado por su excelente desempe침o en el proyecto de caracterizaci칩n de datos</p></i>\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biqFDy1U64Of",
        "outputId": "7c6f91a6-2715-48b5-b726-7175ccb77f29"
      },
      "outputs": [],
      "source": [
        "# Si usted est치 utilizando Colabolatory le puede ser 칰til este c칩digo para cargar los archivos.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    path = '/content/drive/MyDrive/Lab_9'\n",
        "except:\n",
        "    print('Ignorando conexi칩n drive-colab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "2f9c82d204b14515ad27ae07e0b77702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 92,
        "execution_start": 1699544359006,
        "id": "QvMPOqHuI5v-",
        "outputId": "b2d124fd-d859-455f-a05f-7ab4228a9222",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "df = pd.read_csv(f'{path}/sales.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "z3VQgFAppYNU",
        "outputId": "8b61b941-93e2-49d4-f95d-1f66408af975"
      },
      "outputs": [],
      "source": [
        "df['date'] = pd.to_datetime(df['date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b50db6f2cb804932ae3f9e5748a6ea61",
        "deepnote_cell_type": "markdown",
        "id": "pk4ru76pI5v_"
      },
      "source": [
        "## 1. Generando un Baseline (5 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n",
        "</p>\n",
        "\n",
        "Antes de entrenar un algoritmo, usted recuerda los apuntes de su mag칤ster en ciencia de datos y recuerda que debe seguir una serie de *buenas pr치cticas* para entrenar correcta y debidamente su modelo. Despu칠s de un par de vueltas, llega a las siguientes tareas:\n",
        "\n",
        "1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad. [0.5 puntos]\n",
        "2. Implemente un `FunctionTransformer` para extraer el d칤a, mes y a침o de la variable `date`. Guarde estas variables en el formato categorical de pandas. [1 punto]\n",
        "3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos num칠ricos y categ칩ricos. Use `OneHotEncoder` para las variables categ칩ricas. `Nota:` Utilice el m칠todo `.set_output(transform='pandas')` para obtener un DataFrame como salida del `ColumnTransformer` [1 punto]\n",
        "4. Guarde los pasos anteriores en un `Pipeline`, dejando como 칰ltimo paso el regresor `DummyRegressor` para generar predicciones en base a promedios. [0.5 punto]\n",
        "5. Entrene el pipeline anterior y reporte la m칠trica `mean_absolute_error` sobre los datos de validaci칩n. 쮺칩mo se interpreta esta m칠trica para el contexto del negocio? [0.5 puntos]\n",
        "6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los par치metros por default**. 쮺칩mo cambia el MAE al implementar este algoritmo? 쮼s mejor o peor que el `DummyRegressor`? [1 punto]\n",
        "7. Guarde ambos modelos en un archivo .pkl (uno cada uno) [0.5 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvOwzjEo_sHG"
      },
      "outputs": [],
      "source": [
        "from sklearn import set_config\n",
        "set_config(transform_output=\"pandas\")\n",
        "# 1\n",
        "# Se separa la columna que se desea predecir la cual corresponde a quantity\n",
        "X = df.drop(columns=['quantity'])\n",
        "y = df['quantity']\n",
        "\n",
        "# Se separan los datos de entrenamiento, validaci칩n y test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_temporal, X_test, y_temporal, y_test = train_test_split(X, y, test_size=0.1, random_state=444)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temporal, y_temporal, test_size=0.222, random_state=444)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5F0ItkVA2_k"
      },
      "outputs": [],
      "source": [
        "# 2\n",
        "# Se implementa un FunctionTransformer para extraer el d칤a, mes y a침o de la variable date. Se guardan estas variables en el formato categorical de pandas\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "def fecha_date(df):\n",
        "    df['day'] = df['date'].dt.day.astype('category')\n",
        "    df['month'] = df['date'].dt.month.astype('category')\n",
        "    df['year'] = df['date'].dt.year.astype('category')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9O5Ixy2BnZq"
      },
      "outputs": [],
      "source": [
        "#3 Implemente un ColumnTransformer para procesar de manera adecuada los datos num칠ricos y categ칩ricos.\n",
        "# Use OneHotEncoder para las variables categ칩ricas. Nota: Utilice el m칠todo .set_output(transform='pandas') para obtener un DataFrame como salida del ColumnTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "var_categoricas=['city','shop','brand','container','capacity']\n",
        "var_minmaxScaler=['price','lat','long']\n",
        "var_date=['date']\n",
        "var_non=['pop']\n",
        "\n",
        "#Se crea un pipeline_date para que no existan problemas posteriores con el tipo de la columna\n",
        "pipeline_date = Pipeline(steps=[('Parse_date',FunctionTransformer(fecha_date)),\n",
        "                                ('OneHotEncoder', OneHotEncoder(sparse_output=False))\n",
        "                                ])\n",
        "\n",
        "column_transformer=ColumnTransformer([('MinMax Scaler', MinMaxScaler(), var_minmaxScaler),\n",
        "                                      ('One Hot Encoder', OneHotEncoder(sparse_output=False), var_categoricas),\n",
        "                                      ('parse_Date', pipeline_date, var_date),\n",
        "                                      ('Non', 'passthrough', var_non)\n",
        "                                      ]).set_output(transform='pandas')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "_XVKx8OGxzvQ",
        "outputId": "d51e3c4a-10fa-4452-8f4a-bd843b007da3"
      },
      "outputs": [],
      "source": [
        "column_transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiSx4KAQw5o0"
      },
      "outputs": [],
      "source": [
        "#4\n",
        "#Guarde los pasos anteriores en un Pipeline, dejando como 칰ltimo paso el regresor DummyRegressor para generar predicciones en base a promedios\n",
        "\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from xgboost import XGBRegressor\n",
        "pipeline_dummy = Pipeline(steps=[('preprocessor', column_transformer),\n",
        "                                 ('Dummy_reg', DummyRegressor(strategy='mean'))])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tubgQj0JxaRi"
      },
      "outputs": [],
      "source": [
        "#5\n",
        "#Entrene el pipeline anterior y reporte la m칠trica mean_absolute_error sobre los datos de validaci칩n\n",
        "pipeline_dummy.fit(X_train, y_train)\n",
        "y_pred_dummy = pipeline_dummy.predict(X_val)\n",
        "mae_dummy = mean_absolute_error(y_val, y_pred_dummy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38cdvgs21kaO",
        "outputId": "97d941d2-ca40-4a10-aea0-8a33b4b5b366"
      },
      "outputs": [],
      "source": [
        "mae_dummy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoblXpU2o98z"
      },
      "source": [
        "쮺칩mo se interpreta esta m칠trica para el contexto del negocio?\n",
        "\n",
        "Interpretando este valor en el contexto del negocio, corresponder칤a a que la predicci칩n se encuentra con un error de 13000 unidades aproximadamente de su valor real. Indicando que es un mal modelo para predecir las cantidades requeridas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgwjC8hzpBpc"
      },
      "outputs": [],
      "source": [
        "#6\n",
        "#Vuelva a entrenar el Pipeline pero esta vez usando XGBRegressor como modelo utilizando los par치metros por default.\n",
        "pipeline_xgb = Pipeline(steps=[('preprocessor', column_transformer),\n",
        "                               ('regressor', XGBRegressor(enable_categorical=True))])\n",
        "pipeline_xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = pipeline_xgb.predict(X_val)\n",
        "mae_xgb = mean_absolute_error(y_val, y_pred_xgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHuSVbf_r7gU",
        "outputId": "b234a3dd-c9ec-432c-df5e-d9fbf58de069"
      },
      "outputs": [],
      "source": [
        "mae_xgb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqBviAF0iqFT"
      },
      "source": [
        "쮺칩mo cambia el MAE al implementar este algoritmo? 쮼s mejor o peor que el DummyRegressor?\n",
        "\n",
        "Se puede observar una disminuci칩n notable en el MAE del algoritmo disminuyendo de 13000 a 2600. Este modelo presenta una clara mejora en relacion al dummyregressor anteriormente utilizado mostrando valores menores de MAE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2cZQSz9q5Vg",
        "outputId": "56fd5e03-4f26-4e9e-9ef5-e337ac602b39"
      },
      "outputs": [],
      "source": [
        "#7 SOLO USAR ANTES DE ENTREGAR PARA NO TENER 1000 pkls\n",
        "#Guarde ambos modelos en un archivo .pkl\n",
        "import joblib\n",
        "joblib.dump(pipeline_dummy, f'{path}/pipeline_dummy.pkl')\n",
        "joblib.dump(pipeline_xgb, f'{path}/pipeline_xgb.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7e17e46063774ec28226fe300d42ffe0",
        "deepnote_cell_type": "markdown",
        "id": "wnyMINdKI5v_"
      },
      "source": [
        "## 2. Forzando relaciones entre par치metros con XGBoost (10 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n",
        "</p>\n",
        "\n",
        "Un colega aficionado a la econom칤a le *sopla* que la demanda guarda una relaci칩n inversa con el precio del producto. Motivado para impresionar al querido corp칩reo, se propone hacer uso de esta informaci칩n para mejorar su modelo realizando las siguientes tareas:\n",
        "\n",
        "1. Vuelva a entrenar el `Pipeline` con `XGBRegressor`, pero esta vez forzando una relaci칩n mon칩tona negativa entre el precio y la cantidad. Para aplicar esta restricci칩n ap칩yese en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentaci칩n</a>. [6 puntos]\n",
        "\n",
        ">Hint 1: Para implementar el constraint se le sugiere hacerlo especificando el nombre de la variable. De ser as칤, probablemente le sea 칰til **mantener el formato de pandas** antes del step de entrenamiento.\n",
        "\n",
        ">Hint 2: Puede obtener el nombre de las columnas en el paso anterior al modelo regresor mediante el m칠todo `.get_feature_names_out()`\n",
        "\n",
        "2. Luego, vuelva a reportar el `MAE` sobre el conjunto de validaci칩n. [1 puntos]\n",
        "\n",
        "3. 쮺칩mo cambia el error al incluir esta relaci칩n? 쯊en칤a raz칩n su amigo? [2 puntos]\n",
        "\n",
        "4. Guarde su modelo en un archivo .pkl [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "f469f3b572be434191d2d5c3f11b20d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "deepnote_cell_type": "code",
        "id": "B7tMnkiAI5v_",
        "outputId": "3023ca4a-1b57-4ca8-cee2-69985167a001"
      },
      "outputs": [],
      "source": [
        "#1\n",
        "#volver a entrenar el pipeline con XGBRegressor, forzando una relacion monotona negativa entre precio y cantidad\n",
        "monotone_constraint = {'MinMax Scaler__price': -1}\n",
        "pipeline_xgb_forced = Pipeline(steps=[('preprocessor', column_transformer),\n",
        "                               ('regressor', XGBRegressor(enable_categorical=True, monotone_constraints=monotone_constraint))])\n",
        "#entreno pipeline\n",
        "pipeline_xgb_forced.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz49QM2uifsS"
      },
      "outputs": [],
      "source": [
        "#2\n",
        "#volver a reportar el MAE sobre el conjunto de validacion\n",
        "pipeline_xgb_forced.fit(X_train, y_train)\n",
        "y_pred_xgb_forced = pipeline_xgb_forced.predict(X_val)\n",
        "mae_xgb_forced = mean_absolute_error(y_val, y_pred_xgb_forced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noRYDdHD2dLu",
        "outputId": "c9f5caf1-6dca-42cb-9bbd-d18b8b62f0a5"
      },
      "outputs": [],
      "source": [
        "mae_xgb_forced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq97VjhPirG8"
      },
      "source": [
        "*3. 쮺omo cambia el error al incluir esta relacion? 쯦enia razon su amigo?*\n",
        "\n",
        "Al incluir la relaci칩n se puede observar un m칤nimo cambio en el MAE obtenido por lo que se puede concluir que la relaci칩n entre el precio y la cantidad no es tan influyente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS-7D_4niosO",
        "outputId": "7fe7b83b-99a1-4858-e802-55fbc7603824"
      },
      "outputs": [],
      "source": [
        "#4. Guardar modelo en archivo .pkl\n",
        "joblib.dump(pipeline_xgb_forced, f'{path}/pipeline_xgb_forced.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e59ef80ed20b4de8921f24da74e87374",
        "deepnote_cell_type": "markdown",
        "id": "5D5-tX4dI5v_"
      },
      "source": [
        "## 3. Optimizaci칩n de Hiperpar치metros con Optuna (20 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n",
        "</p>\n",
        "\n",
        "Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun m치s* su modelo. En particular, le comenta de la optimizaci칩n de hiperpar치metros con metodolog칤as bayesianas a trav칠s del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n",
        "\n",
        "A partir de la mejor configuraci칩n obtenida en la secci칩n anterior, utilice `optuna` para optimizar sus hiperpar치metros. En particular, se pide que su optimizaci칩n considere lo siguiente:\n",
        "\n",
        "- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n",
        "- Utilice `TPESampler` como m칠todo de muestreo\n",
        "- De `XGBRegressor`, optimice los siguientes hiperpar치metros:\n",
        "    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n",
        "    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n",
        "    - `max_depth` buscando valores enteros en el rango (3, 10)\n",
        "    - `max_leaves` buscando valores enteros en el rango (0, 100)\n",
        "    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n",
        "    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n",
        "    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n",
        "- De `OneHotEncoder`, optimice el hiperpar치metro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n",
        "\n",
        "Para ello se pide los siguientes pasos:\n",
        "1. Implemente una funci칩n `objective()` que permita minimizar el `MAE` en el conjunto de validaci칩n. Use el m칠todo `.set_user_attr()` para almacenar el mejor pipeline entrenado. [10 puntos]\n",
        "2. Fije el tiempo de entrenamiento a 5 minutos. [1 punto]\n",
        "3. Optimizar el modelo y reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto? [3 puntos]\n",
        "4. Explique cada hiperpar치metro y su rol en el modelo. 쮿acen sentido los rangos de optimizaci칩n indicados? [5 puntos]\n",
        "5. Guardar su modelo en un archivo .pkl [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "de5914621cc64cb0b1bacb9ff565a97e",
        "deepnote_cell_type": "code",
        "id": "kMXXi1ckI5v_"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "# Inserte su c칩digo ac치\n",
        "\n",
        "def objective(trial):\n",
        "    #minimizar el MAE en el conjunto de validacion, usando el metodo .set_user_attr() para almacenar el mejor pipeline entrenado\n",
        "    min_frequency = trial.suggest_float('min_frequency', 0.0, 1.0)\n",
        "\n",
        "    pipeline_date = Pipeline(steps=[('Parse_date',FunctionTransformer(fecha_date)),\n",
        "                                ('OneHotEncoder', OneHotEncoder(sparse_output=False, min_frequency=min_frequency))\n",
        "                                ])\n",
        "\n",
        "    #Definir los hiperpar치metros a optimizar\n",
        "    xgbr_regressor_hiperparametros={\n",
        "        'learning_rate' : trial.suggest_float('learning_rate', 0.001, 0.1),\n",
        "        'n_estimators' : trial.suggest_int('n_estimators', 50, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'max_leaves': trial.suggest_int('max_leaves', 0, 100),\n",
        "        'min_child_weight' : trial.suggest_int('min_child_weight', 1, 5),\n",
        "        'reg_alpha' : trial.suggest_float('reg_alpha', 0, 1),\n",
        "        'reg_lambda' : trial.suggest_float('reg_lambda', 0, 1)\n",
        "        }\n",
        "\n",
        "    column_transformer=ColumnTransformer([('MinMax Scaler', MinMaxScaler(), var_minmaxScaler),\n",
        "                                      ('One Hot Encoder', OneHotEncoder(sparse_output=False,min_frequency=min_frequency), var_categoricas),\n",
        "                                      ('parse_Date', pipeline_date,var_date),\n",
        "                                      ('Non', 'passthrough', var_non)\n",
        "                                      ])\n",
        "\n",
        "    pipeline_xgb_optuna = Pipeline([\n",
        "                                ('preprocessor', column_transformer),\n",
        "                               ('xgb_regressor', XGBRegressor(**xgbr_regressor_hiperparametros,\n",
        "                                                              random_state=444))\n",
        "                               ])\n",
        "    pipeline_xgb_optuna.fit(X_train, y_train)\n",
        "    y_pred_xgb_optuna = pipeline_xgb_optuna.predict(X_val)\n",
        "    mae_xgb_optuna = mean_absolute_error(y_val, y_pred_xgb_optuna)\n",
        "    trial.set_user_attr('best_pipeline', pipeline_xgb_optuna)\n",
        "\n",
        "    return mae_xgb_optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "388be011a03b4ccdb74874fa488d8618",
            "6d19d8f88ff74498b8d5f71067feca99",
            "94f0e21e45c04420ac00cc54fe7df2c4",
            "138edf082d6c4cb8b3a4283a4f2c2813",
            "6a3176604dea4f138209a0d5e543830f",
            "05712fb66e844dc798d3c0bfbed6f8c0",
            "3818472f6a4a46ae9e5124b520b70152",
            "8c6bddbcea154d2089efb84d7534ce91",
            "7aa2f84703b9408398a83e4ec036e089",
            "def0af3e720040598b3607259e58b731",
            "8e79c6791e874899b83a338a43d7e3f5"
          ]
        },
        "id": "8HQnV5D5u4MO",
        "outputId": "fc40702a-ae71-43b7-a882-1dd2bb2be609"
      },
      "outputs": [],
      "source": [
        "#2 fijar el entrenamiento a 5 minutos\n",
        "study = optuna.create_study(sampler=TPESampler(seed=444), direction='minimize')\n",
        "study.optimize(objective, timeout=300, show_progress_bar=True) #5*60=300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2GkRKcnvIVY",
        "outputId": "c194c168-fe4e-4e85-86fa-18ed3f650003"
      },
      "outputs": [],
      "source": [
        "#3 Optimizar el modelo y reportar el n칰mero de trials, el MAE y los mejores hiperpar치metros encontrados.\n",
        "mejores_hiperparametros = study.best_params\n",
        "mejor_mae=study.best_value\n",
        "print(f'Mejores hiperpar치metros: {mejores_hiperparametros}')\n",
        "print(f'Mejor MAE: {mejor_mae}')\n",
        "print(f'N칰mero de Trials:{len(study.trials)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdyPQfJtvM2W"
      },
      "source": [
        "*4.Explique cada hiperpar치metro y su rol en el modelo. 쮿acen sentido los rangos de optimizaci칩n indicados?*\n",
        "\n",
        "\n",
        "\n",
        "1.   Learning_rate: Es la tasa de aprendizaje, es decir que va a determinar la rapidez con la que aprende el modelo. Entre m치s baja la tasa, m치s lento aprende el modelo y el valor de 0.08 no es tan baja dentro del rango dado por ende el modelo podr칤a considerarse como de aprendizaje r치pido.\n",
        "2.   n_estimators: Son los n칰meros de 치rboles que se construyen, entre m치s alto su valor, m치s eficiente.  \n",
        "3.  max_depth: Es la profundidad m치xima de cada 치rbol, entre m치s profundo m치s complejo, pero esto podr칤a provocar sobreajustes.\n",
        "4. max_leaves: Es el n칰mero m치ximo de hojas en cada 치rbol, funciona similar a max_depth\n",
        "5. min_child_weight: Controla la cantidad m칤nima de instancias de muestra necesarias en un nodo hoja. Entre m치s bajo su valor, se cpturan relaciones m치s detalladas y en forma opuesta, entre m치s alto el valor, m치s robusto se vuelve el modelo.\n",
        "6. reg_alpha: Controla la magnitud absoluta de los pesos de las hojas, este parametro permite eliminar caracteristicas irrelevantes, lo que ayuda a prevenir el sobreajuste.\n",
        "7. reg_lambda: Funciona similar a reg_alpha, pero se diferencia en que evita que el modelo se generalice.\n",
        "8. min_frequency: Permite filtrar caracteristicas que aparecen con menos frecuencia.\n",
        "\n",
        "\n",
        "Los rangos de optimizaci칩n indicados nos parecen acordes, pero genera ruido que max_leaves, reg_alpha, reg_lambda y min_frequecy puedan ser 0 ya que esto implica que ciertas caracteristicas no tengan frecuencia y se eliminen, que el modelo se generalize y que no se eliminen carcateristicas irrelevantes (esto podr칤a deteriorar las m칠tricas al ser entrenado el modelo ya que tendr치 caracteristicas que no suman al entrenamiento).\n",
        "       \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPZkkPWUyWYx",
        "outputId": "ab080de1-0636-4dcd-a750-9e4c9feb66c4"
      },
      "outputs": [],
      "source": [
        "mejores_hiperparametros['min_frequency']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "Q_0d86ObyOrc",
        "outputId": "cf0ea103-1985-4e84-b922-b9db362b9d3f"
      },
      "outputs": [],
      "source": [
        "#redefino los hiperparametros para optimizar\n",
        "min_frequency_best=mejores_hiperparametros['min_frequency']\n",
        "xgb_mejores_hiperparametros = {\n",
        "\n",
        "'learning_rate':mejores_hiperparametros['learning_rate'],\n",
        "'n_estimators':mejores_hiperparametros['n_estimators'],\n",
        "'max_depth':mejores_hiperparametros['max_depth'],\n",
        "'max_leaves':mejores_hiperparametros['max_leaves'],\n",
        "'min_child_weight':mejores_hiperparametros['min_child_weight'],\n",
        "'reg_alpha':mejores_hiperparametros['reg_alpha'],\n",
        "'reg_lambda':mejores_hiperparametros['reg_lambda']}\n",
        "#redefino los pipelines en base a lo anterior\n",
        "pipeline_date_best=Pipeline(steps=[('Parse_date',FunctionTransformer(fecha_date)),\n",
        "                                ('OneHotEncoder', OneHotEncoder(sparse_output=False, min_frequency=min_frequency_best))\n",
        "                                ])\n",
        "column_transformer_best=ColumnTransformer([('MinMax Scaler', MinMaxScaler(), var_minmaxScaler),\n",
        "                                      ('One Hot Encoder', OneHotEncoder(sparse_output=False,min_frequency=min_frequency_best), var_categoricas),\n",
        "                                      ('parse_Date', pipeline_date_best, var_date),\n",
        "                                      ('Non', 'passthrough', var_non)\n",
        "                                      ])\n",
        "pipeline_xgb_optuna_best=Pipeline([\n",
        "                                ('preprocessor', column_transformer_best),\n",
        "                               ('xgb_regressor', XGBRegressor(**xgb_mejores_hiperparametros,\n",
        "                                                              random_state=444))\n",
        "                               ])\n",
        "#fit\n",
        "pipeline_xgb_optuna_best.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl8MkqN3vOp0",
        "outputId": "617c38a7-ab84-4dff-f3cb-d70ac8510a36"
      },
      "outputs": [],
      "source": [
        "#5 guardar en pkl\n",
        "#import joblib\n",
        "joblib.dump(pipeline_xgb_optuna_best, f'{path}/pipeline_xgb_optuna_best.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5195ccfc37e044ad9453f6eb2754f631",
        "deepnote_cell_type": "markdown",
        "id": "ZglyD_QWI5wA"
      },
      "source": [
        "## 4. Optimizaci칩n de Hiperpar치metros con Optuna y Prunners (17 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n",
        "</p>\n",
        "\n",
        "Despu칠s de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en s칤 mismo. Despu칠s de leer un par de post de personas de dudosa reputaci칩n en la *deepweb*, usted llega a la conclusi칩n que puede cumplir este objetivo mediante la implementaci칩n de **Prunning**.\n",
        "\n",
        "Vuelva a optimizar los mismos hiperpar치metros que la secci칩n pasada, pero esta vez utilizando **Prunning** en la optimizaci칩n. En particular, usted debe:\n",
        "\n",
        "- Responder: 쯈u칠 es prunning? 쮻e qu칠 forma deber칤a impactar en el entrenamiento? [2 puntos]\n",
        "- Redefinir la funci칩n `objective()` utilizando `optuna.integration.XGBoostPruningCallback` como m칠todo de **Prunning** [10 puntos]\n",
        "- Fijar nuevamente el tiempo de entrenamiento a 5 minutos [1 punto]\n",
        "- Reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto? [3 puntos]\n",
        "- Guardar su modelo en un archivo .pkl [1 punto]\n",
        "\n",
        "Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n",
        "\n",
        "```\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "```\n",
        "\n",
        "De implementar la opci칩n anterior, pueden especificar `show_progress_bar = True` en el m칠todo `optimize` para *m치s sabor*.\n",
        "\n",
        "Hint: Si quieren especificar par치metros del m칠todo .fit() del modelo a trav칠s del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n",
        "\n",
        "Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementaci칩n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWO1NPwH5XdW",
        "outputId": "ba5ba90d-68b9-41b4-cd50-61e65b0b9bf4"
      },
      "outputs": [],
      "source": [
        "!pip install optuna-integration[xgboost]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKaFYA5Dz1sy"
      },
      "source": [
        "1. El prunning corresponde a una t칠cnica utilizada para la optimizaci칩n de hiperpar치metros y reducir el tiempo de entrenamiento al descartar ensayos poco viables en las etapas iniciales. En lugar de terminar el entrenamiento de todos los ensayos, revisa los resultados parciales y detiene aquellos que no est치n rindiendo lo suficiente, permitiendo concentrar los recursos en las configuraciones con m치s potencial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxH4uaXKi6eR"
      },
      "outputs": [],
      "source": [
        "# import optuna\n",
        "from optuna.integration import XGBoostPruningCallback\n",
        "import xgboost as xgb\n",
        "# from optuna.samplers import TPESampler\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# Se redefine la funci칩n objetive\n",
        "def objective(trial):\n",
        "  #Se definen los hiperparametros para XGBoost\n",
        "\n",
        "  learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1)\n",
        "  n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n",
        "  max_depth = trial.suggest_int('max_depth', 3, 10)\n",
        "  max_leaves = trial.suggest_int('max_leaves', 0, 100)\n",
        "  min_child_weight = trial.suggest_int('min_child_weight', 1, 5)\n",
        "  reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n",
        "  reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n",
        "\n",
        "\n",
        "  #Se define el hiperparametro para OneHotEncoder\n",
        "  min_frequency = trial.suggest_float('min_frequency', 0.0, 1.0)\n",
        "\n",
        "  column_transformer=ColumnTransformer([('MinMax Scaler', MinMaxScaler(), var_minmaxScaler),\n",
        "                                      ('One Hot Encoder', OneHotEncoder(sparse_output=False,min_frequency=min_frequency), var_categoricas),\n",
        "                                      ('parse_Date', pipeline_date,var_date),\n",
        "                                      ('Non', 'passthrough', var_non)\n",
        "                                      ])\n",
        "\n",
        "  #Se preprocesan los datos para XGBoost\n",
        "  X_train_pruning = column_transformer.fit_transform(X_train)\n",
        "  X_val_pruning = column_transformer.transform(X_val)\n",
        "\n",
        "  #Se preparan los datos para poder utilizarlos en XGBoost\n",
        "  dtrain = xgb.DMatrix(X_train_pruning, label=y_train)\n",
        "  dval = xgb.DMatrix(X_val_pruning, label=y_val)\n",
        "\n",
        "  #Se agrega el pruningcallback\n",
        "  pruning_callback = XGBoostPruningCallback(trial, \"validation-mae\")\n",
        "\n",
        "  #Se entrena el modelo de XGboost\n",
        "  evals = [(dtrain, \"train\"), (dval, \"validation\")]\n",
        "  model_params = {\n",
        "      'objective': 'reg:squarederror',\n",
        "      'eval_metric': 'mae',\n",
        "      'learning_rate': learning_rate,\n",
        "      'max_depth': max_depth,\n",
        "      'max_leaves': max_leaves,\n",
        "      'min_child_weight': min_child_weight,\n",
        "      'reg_alpha': reg_alpha,\n",
        "      'reg_lambda': reg_lambda,\n",
        "      'verbosity': 0\n",
        "  }\n",
        "\n",
        "  model_pruning = xgb.train(\n",
        "      params=model_params,\n",
        "      dtrain=dtrain,\n",
        "      num_boost_round=n_estimators,\n",
        "      evals=evals,\n",
        "      early_stopping_rounds=10,\n",
        "      callbacks=[pruning_callback],\n",
        "      verbose_eval=False #Para que no escupa 1000 l칤neas de c칩digo\n",
        "  )\n",
        "\n",
        "  #Se predice, se calcula el mae y se almacena lo mejor\n",
        "  y_pred_xgb_optuna_pruning = model_pruning.predict(dval)\n",
        "  mae_xgb_optuna_pruning = mean_absolute_error(y_val, y_pred_xgb_optuna_pruning)\n",
        "  trial.set_user_attr('best_model_pruning', model_pruning)\n",
        "\n",
        "  return mae_xgb_optuna_pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0bd9a80e5c1949538b3974e3fd231470",
            "eb122151efa44537af02c6487bb8eee3",
            "abfcd5ad82484a03869345c1ebd28c7d",
            "df2f909056d64c66972dd6ba29bc705c",
            "55a466b8d17747b1868754041e724069",
            "7ef57a5a2e2f411a9be31ae928966769",
            "2923a99e8dbe406d9e5507f72f406e18",
            "9be09c3b1e3c43cdbf47340f30a7f965",
            "9ab59761655d4d72abe450b241b0432a",
            "607b36cb6d7e47c9a125cc9a1bbcfba2",
            "a7ebe197e72444c196f2f8a69b2483fc"
          ]
        },
        "id": "BXwUfYIEp0yl",
        "outputId": "7be335a9-41e1-439c-d2c8-ab22ee1da8c8"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(sampler=TPESampler(seed=444), direction='minimize')\n",
        "study.optimize(objective, timeout=300, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02guMl1jqXpv",
        "outputId": "770b87cd-e444-4b7b-f347-bada822b56b9"
      },
      "outputs": [],
      "source": [
        "mejores_hiperparametros_pruning = study.best_params\n",
        "mejor_mae_pruning = study.best_value\n",
        "print(f'Mejores hiperpar치metros: {mejores_hiperparametros_pruning}')\n",
        "print(f'Mejor MAE: {mejor_mae_pruning}')\n",
        "print(f'N칰mero de Trials:{len(study.trials)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WSUcW6TR8fj",
        "outputId": "a42eca7f-13b4-4f80-9a0c-724d34541514"
      },
      "outputs": [],
      "source": [
        "study.best_trial.user_attrs[\"best_model_pruning\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncNVz84evQa5"
      },
      "source": [
        "Se puede analizar que se realizaron mayores cantidades de Trials para ajustarse de mejor manera a los par치metros utilizados. A pesar de esto no se obtuvieron mejores resultados a la secci칩n anterior. Esto se puede deber a el funcionamiento del pruning, ya que este proceso puede acortar trials si no ve un buen funcionamiento de este por lo que podr칤a estar eliminando trials que finalmente tendr칤an buenos resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcm8W3pcBEjT",
        "outputId": "b43044e2-8d7a-4026-f6f7-dae1bcf54451"
      },
      "outputs": [],
      "source": [
        "# Guardar el modelo en un archivo .pkl\n",
        "best_model_pruning = study.best_trial.user_attrs[\"best_model_pruning\"]\n",
        "joblib.dump(best_model_pruning, f'{path}/pruning_model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "8a081778cc704fc6bed05393a5419327",
        "deepnote_cell_type": "markdown",
        "id": "ZMiiVaCUI5wA"
      },
      "source": [
        "## 5. Visualizaciones (5 puntos)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n",
        "</p>\n",
        "\n",
        "\n",
        "Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n",
        "\n",
        "A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n",
        "\n",
        "1. Gr치fico de historial de optimizaci칩n [1 punto]\n",
        "2. Gr치fico de coordenadas paralelas [1 punto]\n",
        "3. Gr치fico de importancia de hiperpar치metros [1 punto]\n",
        "\n",
        "Comente sus resultados:\n",
        "\n",
        "4. 쮻esde qu칠 *trial* se empiezan a observar mejoras notables en sus resultados? [0.5 puntos]\n",
        "5. 쯈u칠 tendencias puede observar a partir del gr치fico de coordenadas paralelas? [1 punto]\n",
        "6. 쮺u치les son los hiperpar치metros con mayor importancia para la optimizaci칩n de su modelo? [0.5 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "0e706dc9a8d946eda7a9eb1f0463c6d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "deepnote_cell_type": "code",
        "id": "xjxAEENAI5wA",
        "outputId": "b0ad43d3-206a-4427-b082-d5f425f2ae85"
      },
      "outputs": [],
      "source": [
        "# Inserte su c칩digo ac치\n",
        "import optuna.visualization as vis\n",
        "#historial de optimizaci칩n\n",
        "fig1 = vis.plot_optimization_history(study)\n",
        "fig1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_4kAhycxvOZ"
      },
      "source": [
        "Se puede observar que desde el trial n췈7 se generan mejoras considerables en el MAE generado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "66obOpftxMiq",
        "outputId": "119d3a31-76e1-4ba3-f917-8b6bf116f320"
      },
      "outputs": [],
      "source": [
        "#coordenadas paralelas\n",
        "fig2 = vis.plot_parallel_coordinate(study)\n",
        "fig2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEnA9I3ux3ii"
      },
      "source": [
        "Se pueden observar los valores m치ximos para max_depths(10), max_leaves(100) y min_child_weight(5) indicando que mientras se presente un mayor valor, mejores resultados se obtienen, al igual que con n_estimators. Adem치s se ven valores altos para reg_alpha y reg_alpha pero se puede observar que no tienen un gran impacto general en el valor objetivo. Finalmente se puede observar que con una menor min_frecuency se obtienen mejores resultados objetivos adem치s de mantener un valor de learning_rate no muy alto (para evitar subajsute) y muy bajo (para evitar sobreajuste)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "JiHhaW27xPjc",
        "outputId": "85fc32f7-e5bc-4d6a-c3ac-3afddb2ac9c6"
      },
      "outputs": [],
      "source": [
        "#importancia parametros\n",
        "fig3 = vis.plot_param_importances(study)\n",
        "fig3.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7a_qohizRPX"
      },
      "source": [
        "Se puede ver claramente que los hiperpar치metros que m치s importancia tienen en el modelo corresponden al learning_rate utilizado por lo antes mencionado y la min_frecuency ya que este mientras menor sea se presentaban resultados 칩ptimos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac8a20f445d045a3becf1a518d410a7d",
        "deepnote_cell_type": "markdown",
        "id": "EoW32TA9I5wA"
      },
      "source": [
        "## 6. S칤ntesis de resultados (3 puntos)\n",
        "\n",
        "Finalmente:\n",
        "\n",
        "1. Genere una tabla resumen del MAE en el conjunto de validaci칩n obtenido en los 5 modelos entrenados desde Baseline hasta XGBoost con Constraints, Optuna y Prunning. [1 punto]\n",
        "2. Compare los resultados de la tabla y responda, 쯤u칠 modelo obtiene el mejor rendimiento? [0.5 puntos]\n",
        "3. Cargue el mejor modelo, prediga sobre el conjunto de **test** y reporte su MAE. [0.5 puntos]\n",
        "4. 쮼xisten diferencias con respecto a las m칠tricas obtenidas en el conjunto de validaci칩n? 쯇orqu칠 puede ocurrir esto? [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jq5C6cDnJg9h",
        "outputId": "195e4ab5-73dc-4946-c92f-8d774dd87918"
      },
      "outputs": [],
      "source": [
        "#1. genere una tabla resumen del MAE en el conjunto de validacion obtenido en los 5 modelos entrenados desde baseline hasta XGBoost con constrains, optune y prunning\n",
        "df_resume_mae=pd.DataFrame(columns=['Modelo','MAE'])\n",
        "#relleno el df\n",
        "df_resume_mae.loc[0]=['Baseline',mae_dummy]\n",
        "df_resume_mae.loc[1]=['XGBoost',mae_xgb]\n",
        "df_resume_mae.loc[2]=['XGBoost con Constraints',mae_xgb_forced]\n",
        "df_resume_mae.loc[3]=['XGBoost con Optuna',mejor_mae]\n",
        "df_resume_mae.loc[4]=['XGBoost con Prunning',mejor_mae_pruning]\n",
        "df_resume_mae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNHP-HniH-m4"
      },
      "source": [
        "*2. Comparaci칩n de resultados y mejor rendimiento*\n",
        "\n",
        "El mejor rendimiento lo obtiene el modelo XGBoost con Optuna dado que posee el menor valor de MAE y entre menor sea este valor, menos errores posee el modelo al momento de predecir.\n",
        "\n",
        "El m칠todo que usa Prunning (est칠 se encarga de podar) podr칤a hacer pensar que ser칤a el mejor modelo al realizar podaciones, pero Optuna obtiene los mejores hiperparametros para lograr la mejor m칠trica entre todos los modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prnmunnGSxGc",
        "outputId": "f643e86f-f83b-46d5-8d47-79050827f357"
      },
      "outputs": [],
      "source": [
        "print(path +'/pipeline_xgb_optuna_best.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Apo7bABnIDFF",
        "outputId": "fa43c21d-98d9-467b-d9de-d1fdd96e7000"
      },
      "outputs": [],
      "source": [
        "#3. cargar el mejor modelo, predecir sobre el conjunto de test y reportar MAE\n",
        "mejor_modelo_mae=joblib.load(path +'/pipeline_xgb_optuna_best.pkl')\n",
        "test_pred=mejor_modelo_mae.predict(X_test)\n",
        "mae_test=mean_absolute_error(y_test, test_pred)\n",
        "print(f'MAE en el conjunto de test: {mae_test}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj0WQ8BkIIT7"
      },
      "source": [
        "*4. Existen diferencias respecto a las metricas obtenidas en conjunto val? porque ocurre?*\n",
        "\n",
        "Si existen diferencias respecto a las m칠tricas obtenidas en el conjunto de validaci칩n, pero esta es leve. Incluso es mejor la m칠trica obtenida en el conjunto test que la obtenida en el conjunto de validaci칩n. Esta peque침a diferencia se puede estar produciendo por el tama침o entre los datasets (validaci칩n, entrenamiento y test), siendo el test el m치s peque침o de los tres y tambi칠n estar칤a afectando la distribuci칩n que tiene cada uno de los sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5c4654d12037494fbd385b4dc6bd1059",
        "deepnote_cell_type": "markdown",
        "id": "E_19tgBEI5wA"
      },
      "source": [
        "# Conclusi칩n\n",
        "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/8CT1AXElF_cAAAAC/gojo-satoru.gif\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5025de06759f4903a26916c80323bf25",
        "deepnote_cell_type": "markdown",
        "id": "Kq2cFix1I5wA"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown",
        "id": "rAp9UxwiI5wA"
      },
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "f63d38450a6b464c9bb6385cf11db4d9",
    "deepnote_persisted_session": {
      "createdAt": "2023-11-09T16:18:30.203Z"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05712fb66e844dc798d3c0bfbed6f8c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd9a80e5c1949538b3974e3fd231470": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb122151efa44537af02c6487bb8eee3",
              "IPY_MODEL_abfcd5ad82484a03869345c1ebd28c7d",
              "IPY_MODEL_df2f909056d64c66972dd6ba29bc705c"
            ],
            "layout": "IPY_MODEL_55a466b8d17747b1868754041e724069"
          }
        },
        "138edf082d6c4cb8b3a4283a4f2c2813": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_def0af3e720040598b3607259e58b731",
            "placeholder": "",
            "style": "IPY_MODEL_8e79c6791e874899b83a338a43d7e3f5",
            "value": "05:01/05:00"
          }
        },
        "2923a99e8dbe406d9e5507f72f406e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3818472f6a4a46ae9e5124b520b70152": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "388be011a03b4ccdb74874fa488d8618": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d19d8f88ff74498b8d5f71067feca99",
              "IPY_MODEL_94f0e21e45c04420ac00cc54fe7df2c4",
              "IPY_MODEL_138edf082d6c4cb8b3a4283a4f2c2813"
            ],
            "layout": "IPY_MODEL_6a3176604dea4f138209a0d5e543830f"
          }
        },
        "55a466b8d17747b1868754041e724069": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "607b36cb6d7e47c9a125cc9a1bbcfba2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a3176604dea4f138209a0d5e543830f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d19d8f88ff74498b8d5f71067feca99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05712fb66e844dc798d3c0bfbed6f8c0",
            "placeholder": "",
            "style": "IPY_MODEL_3818472f6a4a46ae9e5124b520b70152",
            "value": "Besttrial:151.Bestvalue:2092.39:100%"
          }
        },
        "7aa2f84703b9408398a83e4ec036e089": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ef57a5a2e2f411a9be31ae928966769": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c6bddbcea154d2089efb84d7534ce91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e79c6791e874899b83a338a43d7e3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94f0e21e45c04420ac00cc54fe7df2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c6bddbcea154d2089efb84d7534ce91",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7aa2f84703b9408398a83e4ec036e089",
            "value": 300
          }
        },
        "9ab59761655d4d72abe450b241b0432a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9be09c3b1e3c43cdbf47340f30a7f965": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7ebe197e72444c196f2f8a69b2483fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abfcd5ad82484a03869345c1ebd28c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9be09c3b1e3c43cdbf47340f30a7f965",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ab59761655d4d72abe450b241b0432a",
            "value": 300
          }
        },
        "def0af3e720040598b3607259e58b731": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df2f909056d64c66972dd6ba29bc705c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_607b36cb6d7e47c9a125cc9a1bbcfba2",
            "placeholder": "",
            "style": "IPY_MODEL_a7ebe197e72444c196f2f8a69b2483fc",
            "value": "05:01/05:00"
          }
        },
        "eb122151efa44537af02c6487bb8eee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ef57a5a2e2f411a9be31ae928966769",
            "placeholder": "",
            "style": "IPY_MODEL_2923a99e8dbe406d9e5507f72f406e18",
            "value": "Besttrial:101.Bestvalue:2282.39:100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
