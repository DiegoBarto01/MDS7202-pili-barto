{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwCVs8pzA4v_"
      },
      "source": [
        "<h1><center>Laboratorio 8: Predicciones y Recomendaciones üîÆü™Ñ </center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2024</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6idsH0-A77T"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti√°n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicol√°s Ojeda, Melanie Pe√±a, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHCewuvxA-W2"
      },
      "source": [
        "### **Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados**\n",
        "\n",
        "- Nombre de alumno 1: Diego Bartolucci\n",
        "- Nombre de alumno 2: Pilar Nilo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pg5Iz9tegst"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Repositorio](https://github.com/DiegoBarto01/MDS7202-pili-barto.git)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZCCAQyqegsu"
      },
      "source": [
        "## Temas a tratar\n",
        "- Series de Tiempo.\n",
        "- Predicciones v√≠a `Prophet`.\n",
        "- Implementar un sistema de recomendaci√≥n utilizando `surprise`.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C√≥digo que no se pueda ejecutar, no ser√° revisado.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender qu√© es una serie de tiempo y su estructura.\n",
        "- Identificar tendencias, estacionalidades e irregularidades.\n",
        "- Armar un modelo predictivo para la serie.\n",
        "- Conocer y aplicar sistemas de recomendaci√≥n.\n",
        "- Entender estructura y conocer casos de estudio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwmzvkB8p3rc",
        "outputId": "1e4902a4-b8d1-4882-e8a6-462572757b1e"
      },
      "outputs": [],
      "source": [
        "# Si usted est√° utilizando Colabolatory le puede ser √∫til este c√≥digo para cargar los archivos.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    path = '/content/drive/MyDrive/Lab_8'\n",
        "except:\n",
        "    print('Ignorando conexi√≥n drive-colab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "smst0oS3hp9t"
      },
      "outputs": [],
      "source": [
        "# Librerias globales\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKJ0AuRJpDa-"
      },
      "source": [
        "# **1. Forecasting (30 puntos)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q56pg4rpJ2d"
      },
      "source": [
        "## **Prophet**\n",
        "\n",
        "Prophet es una herramienta open-source de Facebook utilizada para realizar predicciones en series de tiempo. Esta se basa en la descomposici√≥n aditiva, donde tendencias no lineales se ajustan junto a la estacionalidad.\n",
        "\n",
        "En la ecuaci√≥n de a continuaci√≥n se puede ver una idea general de los elementos que construyen a un modelo aditivo como lo es Prophet.\n",
        "\n",
        "\\begin{equation}\n",
        "y(t) = g(t) + s(t) + h(t) + e(t)\n",
        "\\end{equation}\n",
        "\n",
        "Donde, $g(t)$ hace referencia a las tendencias, que corresponden a cambios graduales en largos periodos de tiempo. $s(t)$ corresponde a la estacionalidad, son cambios periodicos o cortos en el tiempo. $h(t)$ es el efecto que tienen las festividades sobre las predicciones, mientras que e(t) corresponde al error o ruido. Finalmente $y(t)$, es la predicci√≥n hecha por el modelo.\n",
        "\n",
        "Prophet trabaja por defecto con Piece-Wise Lineal Model, este es un modelo de regresi√≥n lineal, en el cual se buscan distintas zonas en que la data presente patrones o tendencias lineales, de estas zonas obtiene su regresi√≥n y luego las \"une\" de manera de representar toda la regi√≥n, como se puede ver en la ecuaci√≥n siguiente.\n",
        "\n",
        "\\begin{equation}\n",
        "y(x)=\n",
        "    \\begin{cases}\n",
        "        Œ∑_1 + \\beta_1(x-b_1), & b_1 < x  \\leqslant b_2 \\\\\n",
        "        Œ∑_2 + \\beta_2(x-b_2), & b_2 < x  \\leqslant b_3 \\\\\n",
        "        Œ∑_3 + \\beta_3(x-b_3), & b_3 < x  \\leqslant b_3 \\\\\n",
        "        ... \\\\\n",
        "        Œ∑_k + \\beta_{nb}(x-b_{nb-1}), & b_{n-1} < x  \\leqslant b_{nb} \\\\\n",
        "    \\end{cases}\n",
        "\\end{equation}\n",
        "\n",
        "Siendo $b_1$ el primer punto de quiebre en la serie y as√≠ hasta el punto $b_{nb}$ correspondiente al √∫ltimo punto de quiebre de la serie con una cantidad $nb$ de puntos.\n",
        "\n",
        "Para mayor informaci√≥n de Prophet y como utilizarla, pueden ver su [documentaci√≥n](https://facebook.github.io/prophet/docs/quick_start.html#python-api), donde hay pueden encontrar un peque√±o tutorial de la librer√≠a."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4h6rX5sBXmB"
      },
      "source": [
        "## **La Factura de Homero**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHZq_h1RFZJ1"
      },
      "source": [
        "<center>\n",
        "<img src =\"https://i.makeagif.com/media/7-30-2018/H_ZAY1.gif\" width = 500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsrEkIUHBwBb"
      },
      "source": [
        "Homero Simpson ha trabajado en la Planta Nuclear de Springfield por m√°s de 20 a√±os como Inspector de Seguridad, pero recientemente el Sr. Burns le ha permitido trabajar desde casa. Aunque le encanta la flexibilidad que esto le otorga, tambi√©n ha notado un aumento considerable en su consumo energ√©tico en el hogar. Con el uso constante de calefacci√≥n en invierno y aire acondicionado en verano, Homero est√° preocupado por c√≥mo afectar√° esto a su presupuesto en los pr√≥ximos meses, ya que planea pasar a√∫n m√°s tiempo en casa.\n",
        "\n",
        "Afortunadamente, gracias a su puesto en la Planta de Energ√≠a Nuclear, Homero tiene acceso a los datos de consumo de energ√≠a de cada ciudadano en Springfield, por lo que accede a esta informaci√≥n y almacena el consumo de su hogar en un archivo llamado `energia_homero.csv`. Este archivo posee el consumo diario en el hogar de Homero Simpson desde el Junio del 2016 hasta Julio del 2020.\n",
        "\n",
        "Con esta valiosa informaci√≥n, Homero espera poder predecir su consumo energ√©tico y tomar decisiones informadas para ajustar su presupuesto mensual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKnCQlYbFpQ4"
      },
      "source": [
        "Los datos son los siguientes:\n",
        "\n",
        "* **date**: Fecha de medici√≥n.\n",
        "* **Energy_kWh**: Consumo diario de energ√≠a el√©ctrica en el hogar de Homero (en kWh)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obay1DE6H9Hk"
      },
      "source": [
        "## 1.1 Series de Tiempo [0 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIjQdwBAJFLJ"
      },
      "source": [
        "### Carga de los datos\n",
        "\n",
        "En primer lugar, cargue los datos hist√≥ricos del archivo `energia_homero.csv` al entorno de trabajo. Una vez cargados, aseg√∫rense de transformar la columna `date` a formato `datetime`. Adem√°s, visualice el consumo de energ√≠a en la casa de Homero mediante la librer√≠a `plotly`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trz2Q7JKR2Zq"
      },
      "source": [
        "**Respuesta**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0HcBD2JHRtxk",
        "outputId": "725bcbb8-602a-465e-e30e-7631fd368a39"
      },
      "outputs": [],
      "source": [
        "#Se carga el archivo\n",
        "cvs_path = path + '/energia_homero.csv'\n",
        "df_energy = pd.read_csv(cvs_path)\n",
        "\n",
        "#Se transforma la columna date a formato datetime\n",
        "df_energy['date'] = pd.to_datetime(df_energy['date'])\n",
        "\n",
        "#Se visualiza el consumo de energ√≠a en la casa de Homero\n",
        "fig = px.line(df_energy, x='date', y='Energy_kWh', title='Consumo de energ√≠a en la casa de Homero')\n",
        "fig.update_layout(xaxis_title='Fecha', yaxis_title='Consumo de energ√≠a (kWh)')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-aXIm9ZOufL"
      },
      "source": [
        "## 1.2 Controlando la Serie de Tiempo [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYT66o06PYSY"
      },
      "source": [
        "<center>\n",
        "<img src =\"https://i.pinimg.com/originals/66/77/88/667788e0b1f08ff1e1cfce11d303b203.gif\" width = 500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7OIm3yzPcPG"
      },
      "source": [
        "Luego de leer mucho, Homero cree que necesita descomponer la serie de tiempo para poder controlar estos componentes de forma efectiva y lograr que la serie tenga propiedades de una serie estacionaria.\n",
        "\n",
        "Usted, como buen ciudadano de Springfield, decide ayudar a Homero, el cual le pide que realice lo siguientes pasos:\n",
        "\n",
        "0. Cree un conjunto de entrenamiento y uno de prueba (a proyectar). Para ello, considere como entrenamiento la informaci√≥n **hasta** el `2020-02-29` y como conjunto de prueba **desde** el `2020-03-01`. [0 puntos]\n",
        "1. Cree un `Pipeline` que permita obtener una representaci√≥n de la tendencia de la serie de tiempo, mediante un modelo Lineal. Nombre al pipeline `Pipeline_trend`. [1 punto]\n",
        "2. Entrene el modelo lineal y luego obtenga predicciones tanto para el conjunto de entrenamiento como para el de prueba (intervalo completo de tiempo). Luego grafique las predicciones y calcule el `Mean Absolute Error` (MAE), tanto para el conjunto de prueba como para el de entrenamiento. [1 punto]\n",
        "3. Grafique el error (Valor real - Valor predicho) para todo el intervalo de tiempo y responda ¬øHay un comportamiento estacional en la serie? [1 punto]\n",
        "4.  Cree un `Pipeline` que permita modelar la estacionalidad de la serie temporal mediante t√©rminos de Fourier y la represente a trav√©s de una Regresi√≥n Lineal de la variable objetivo. Nombre a este pipeline `Pipeline_seasonal`. Determine el valor de Periodos `P` y el n√∫mero de terminos de Fourier `n`. [1 punto]\n",
        "5. Entrene el nuevo modelo y obtenga predicciones en el intervalo completo de tiempo. Luego grafique y calcule el `MAE` en el conjunto de prueba y en el de entrenamiento. [1 punto]\n",
        "6. Vuelva a graficar el error y comente los resultados. [1 punto]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwz-_XbTSCwX"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "Y77qr78ASEH8"
      },
      "outputs": [],
      "source": [
        "#0\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Se crean los conjuntos de entrenamiento y de test\n",
        "train_df = df_energy[df_energy['date'] <= '2020-02-29']\n",
        "test_df = df_energy[df_energy['date'] >= '2020-03-01']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mlMU_PWzMWHe"
      },
      "outputs": [],
      "source": [
        "#1\n",
        "#Se crea un pipeline para obtener la tendencia de la serie de tiempo\n",
        "pipeline_trend = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('linear_regression', LinearRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nz0jddRhMbL0",
        "outputId": "6dc0cf73-de00-4ac7-83d0-2776223cf7fe"
      },
      "outputs": [],
      "source": [
        "#2\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "#Se entrena el modeo lineal para obtener predicciones para train_df y test_df.\n",
        "pipeline_trend.fit(train_df[['date']], train_df['Energy_kWh'])\n",
        "train_df['trend_pred'] = pipeline_trend.predict(train_df[['date']])\n",
        "test_df['trend_pred'] = pipeline_trend.predict(test_df[['date']])\n",
        "\n",
        "#Se grafican las predicciones y se calcula el Mean Absolute Error (MAE), tanto para test_df como para train_df\n",
        "fig = px.line(train_df, x='date', y=['Energy_kWh', 'trend_pred'], title='Predicciones de la tendencia')\n",
        "fig.update_layout(xaxis_title='Fecha', yaxis_title='Consumo de energ√≠a (kWh)')\n",
        "fig.show()\n",
        "\n",
        "fig = px.line(test_df, x='date', y=['Energy_kWh', 'trend_pred'], title='Predicciones de la tendencia')\n",
        "fig.update_layout(xaxis_title='Fecha', yaxis_title='Consumo de energ√≠a (kWh)')\n",
        "fig.show()\n",
        "\n",
        "#Se calcula el MAE (Mean Absolute Error) para ambos conjuntos\n",
        "mae_train = mean_absolute_error(train_df['Energy_kWh'],train_df['trend_pred'])\n",
        "mae_test = mean_absolute_error(test_df['Energy_kWh'],test_df['trend_pred'])\n",
        "print(f\"MAE en el conjunto de entrenamiento: {mae_train}\")\n",
        "print(f\"MAE en el conjunto de prueba: {mae_test}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ouYyFVuFMmFm",
        "outputId": "e2888799-980c-43ab-8ab4-679ccbd35c15"
      },
      "outputs": [],
      "source": [
        "#3\n",
        "#Se calcula el error\n",
        "predicted_values = np.concatenate([train_df['trend_pred'].values, test_df['trend_pred'].values])\n",
        "error = df_energy['Energy_kWh'].values - predicted_values\n",
        "\n",
        "#Se grafica el error para todo intervalo de tiempo\n",
        "fig = px.line(df_energy, x='date', y=error, title='Error de la tendencia')\n",
        "fig.update_layout(xaxis_title='Fecha', yaxis_title='Error')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzF8e0EXvfdf"
      },
      "source": [
        "En el gr√°fico se presenta cierta estacionalidad y periodicidad para el valor del error adem√°s de una gran variabilidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0w_jL_X3Mu9v"
      },
      "outputs": [],
      "source": [
        "#4\n",
        "#Se crea Pipeline mediante t√©rminos de Fourier y la represente a trav√©s de una Regresi√≥n Lineal\n",
        "# Se inserta lo visto en clases para aplicar Fourier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class TimeTransformer(TransformerMixin, BaseEstimator):\n",
        "    def __init__(self, n = 4, p = 365):\n",
        "\n",
        "        self.init_date = None\n",
        "        self.n = n\n",
        "        self.p = p\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "\n",
        "        '''\n",
        "        Realiza el fit sobre los datos --> guarda la fecha de inicio de entrenamiento.\n",
        "        '''\n",
        "\n",
        "        assert isinstance(X, pd.DataFrame), 'df must be a pandas DataFrame'\n",
        "        assert 'date' in X.columns, 'date must be a column of DataFrame'\n",
        "\n",
        "        self.init_date = X.date.iloc[0]\n",
        "\n",
        "    def transform(self, X):\n",
        "\n",
        "        '''\n",
        "        Realiza el transform sobre el conjunto X, retornando los t√©rminos de fourier.\n",
        "        '''\n",
        "\n",
        "        X = X[['date']].copy()\n",
        "\n",
        "        assert self.init_date is not None, 'transformer must be fitted first!'\n",
        "        assert isinstance(X, pd.DataFrame), 'df must be a pandas Dataframe'\n",
        "        assert 'date' in X.columns, 'date must be a column of DataFrame'\n",
        "\n",
        "        final_date = X.index[-1] # last date of X\n",
        "        final_date = X.date.iloc[-1] # last date of X\n",
        "\n",
        "        # generate trend series\n",
        "        count = (final_date - self.init_date).days + 1\n",
        "        X['trend'] = [i for i in range(count)][-len(X):]\n",
        "\n",
        "        # generate fourier terms\n",
        "        fourier = self.get_fourier_terms(X['trend'], self.n, self.p)\n",
        "\n",
        "        # concatenate trend + fourier\n",
        "        X = pd.concat([X, fourier], axis = 1).drop(columns = 'date')\n",
        "\n",
        "        return X\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "\n",
        "        '''\n",
        "        implementa el m√©todo fit y transform a la vez.\n",
        "        '''\n",
        "\n",
        "        X = X[['date']].copy()\n",
        "\n",
        "        assert isinstance(X, pd.DataFrame), 'df must be a pandas Dataframe'\n",
        "        assert 'date' in X.columns, 'date must be a column of DataFrame'\n",
        "\n",
        "        self.trend = len(X)\n",
        "        self.init_date = X.date.iloc[0]\n",
        "\n",
        "        final_date = X.date.iloc[-1] # last date of X\n",
        "\n",
        "        # generate trend series\n",
        "        count = (final_date - self.init_date).days + 1\n",
        "        X['trend'] = [i for i in range(count)][-len(X):]\n",
        "\n",
        "        # generate fourier terms\n",
        "        fourier = self.get_fourier_terms(X['trend'], self.n, self.p)\n",
        "\n",
        "        # concatenate trend + fourier\n",
        "        X = pd.concat([X, fourier], axis = 1).drop(columns = 'date')\n",
        "\n",
        "        return X\n",
        "\n",
        "    def get_fourier_terms(self, serie, n, p):\n",
        "\n",
        "        '''\n",
        "        Obtiene los t√©rminos de fourier de una serie\n",
        "        '''\n",
        "\n",
        "        terms = []\n",
        "        for i in range(1, n + 1):\n",
        "            sine_term = np.sin(2 * np.pi * i * serie / p)\n",
        "            cosine_term = np.cos(2 * np.pi * i * serie / p)\n",
        "            terms.extend([sine_term, cosine_term])\n",
        "\n",
        "        fourier = np.column_stack(terms)\n",
        "        fourier = pd.DataFrame(fourier, columns = [f'fourier_{i}' for i in range(n * 2)], index = serie.index) # este paso es opcional\n",
        "\n",
        "        return fourier\n",
        "\n",
        "pipeline_seasonal = Pipeline([\n",
        "    ('time_transformer', TimeTransformer(n = 4, p = 365)),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('linear_regression', LinearRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgYXZSk_o5HS"
      },
      "source": [
        "Se utilizar√° una periodicidad de 365 ya que en un a√±o no bisiesto se presentan esta cantidad de d√≠as y se usar√° una cantidad de terminos de 4 ya que con este valor se presentaron los mejores resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aU9QjFWqzciT",
        "outputId": "7235be29-b1d1-4e05-c920-ec42c5a08d9d"
      },
      "outputs": [],
      "source": [
        "#5\n",
        "#Se entrena el nuevo modelo\n",
        "pipeline_seasonal.fit(train_df[['date']], train_df['Energy_kWh'])\n",
        "train_df['seasonal_pred'] = pipeline_seasonal.predict(train_df[['date']])\n",
        "test_df['seasonal_pred'] = pipeline_seasonal.predict(test_df[['date']])\n",
        "\n",
        "#Se grafican las predicciones y se calcula el Mean Absolute Error (MAE), tanto para test_df como para train_df\n",
        "fig = px.line(train_df, x='date', y=['Energy_kWh', 'seasonal_pred'], title='Predicciones de la tendencia')\n",
        "fig.update_layout(xaxis_title='Fecha', yaxis_title='Consumo de energ√≠a (kWh)')\n",
        "fig.show()\n",
        "\n",
        "fig = px.line(test_df, x='date', y=['Energy_kWh', 'seasonal_pred'], title='Predicciones de la tendencia')\n",
        "fig.update_layout(xaxis_title='Fecha', yaxis_title='Consumo de energ√≠a (kWh)')\n",
        "fig.show()\n",
        "\n",
        "#Se calcula el MAE (Mean Absolute Error) para ambos conjuntos\n",
        "mae_train = mean_absolute_error(train_df['Energy_kWh'],train_df['seasonal_pred'])\n",
        "mae_test = mean_absolute_error(test_df['Energy_kWh'],test_df['seasonal_pred'])\n",
        "print(f\"MAE en el conjunto de entrenamiento: {mae_train}\")\n",
        "print(f\"MAE en el conjunto de prueba: {mae_test}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "L9V3pRcXzgEE",
        "outputId": "3d3ae4ee-4a3b-48d7-c27d-6caf5be006ef"
      },
      "outputs": [],
      "source": [
        "#6\n",
        "#Se calcula el error\n",
        "predicted_values_seasonal = np.concatenate([train_df['seasonal_pred'].values, test_df['seasonal_pred'].values])\n",
        "error_seasonal = df_energy['Energy_kWh'].values - predicted_values_seasonal\n",
        "\n",
        "#Se grafica el error para todo intervalo de tiempo\n",
        "fig = px.line(df_energy, x='date', y=error_seasonal, title='Error de la tendencia')\n",
        "fig.update_layout(xaxis_title='Fecha', yaxis_title='Error')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1OCM8NjpVh9"
      },
      "source": [
        "Se puede observar que el error disminuy√≥, infiriendo as√≠ que el modelo representa mejor los datos buscados, adem√°s que el comportamiento que presenta el error tiene m√°s semenjanzas a una onda estacionaria donde se presenta una mayor variabilidad durante los meses de invierno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYclWYijbB9O"
      },
      "source": [
        "## 1.3 Un Consejo para Homero [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXI4w5jdcAML"
      },
      "source": [
        "<center>\n",
        "<img src =\"https://media.tenor.com/sjbvGMLZiDkAAAAM/the-simpsons-homner-simpson.gif\" width = 400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQYcRK_ibGhc"
      },
      "source": [
        "Homero al observar los resultados obtenidos, se mostr√≥ conforme y decidi√≥ no seguir averiguando al respecto. Usted, como buen amigo y utilizando sus recientes conocimientos en Forecast, le sugiere a Homero utilizar **Prophet**, una herramienta de modelado de series de tiempo que incluye descomposici√≥n de tendencias y estacionalidad, as√≠ como la capacidad de incorporar regresores adicionales. Usted le explica a Homero que Prophet es especialmente √∫til para realizar pron√≥sticos cuando hay patrones estacionales y que podr√≠a mejorar los resultados que ha obtenido hasta ahora.\n",
        "\n",
        "Homero, algo agotado debido al exhaustivo estudio que hizo para entender como funciona esta herramienta, le solicita ayuda para implementar Prophet y evaluar si puede obtener mejores resultados en sus predicciones de consumo energ√©tico.\n",
        "\n",
        "Dado esto, Homero le pide que realice los siguientes pasos:\n",
        "\n",
        "1. Instale y cargue Prophet a su entorno de trabajo. Luego renombre la variable temporal `date` por `ds` y la variable objetivo `Energy_kWh` por `y`, en los conjuntos de entrenamiento y de prueba. [1 punto]\n",
        "2. Cree y ajuste el modelo Prophet con sus datos de entrenamiento. Luego realice prepare el dataset de predicciones con su set de prueba y realice las predicciones. `Nota:` Le puede ser √∫til este [Enlace](https://facebook.github.io/prophet/docs/quick_start.html#python-api) [2 puntos]\n",
        "3. Grafique las predicciones y las componentes del modelo Prophet. `Nota`: Utilice los m√©todos `.plot()` y `.plot_components()` de Prophet. [1 punto]\n",
        "4. Calcule el `MAE` de la predicci√≥n en el conjunto de entrenamiento y de prueba. [1 punto]\n",
        "5. Grafique el error (Valor real - Valor predicho) en todo el intervalo de tiempo. Analice sus resultados y responda: ¬øHay un comportamiento estacional en la serie? [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-XmKaQmYoqtp"
      },
      "outputs": [],
      "source": [
        "# librerias extras\n",
        "from prophet import Prophet\n",
        "from prophet.plot import plot_plotly, plot_components_plotly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1eLSZ_uSQxK"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "P9bkU463SPM-"
      },
      "outputs": [],
      "source": [
        "#1\n",
        "#Se adaptan los conjuntos de entrenamiento y test\n",
        "df_energy_prophet = df_energy.rename(columns={'date': 'ds', 'Energy_kWh': 'y'})\n",
        "train_df_prophet = df_energy_prophet[df_energy_prophet['ds'] <= '2020-02-29']\n",
        "test_df_prophet = df_energy_prophet[df_energy_prophet['ds'] >= '2020-03-01']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wRbdVgyK3Nt8",
        "outputId": "e50af771-c500-4e72-d5ef-33ae2a098380"
      },
      "outputs": [],
      "source": [
        "#2\n",
        "#Se crea y ajusta el modelo prophet con los datos de entrenamiento\n",
        "model = Prophet()\n",
        "model.fit(train_df_prophet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9ChXZUqN3pLR"
      },
      "outputs": [],
      "source": [
        "#Se prepara el dataset de predicciones con su set de prueba y realice las predicciones.\n",
        "future = pd.DataFrame({'ds': test_df_prophet['ds']})\n",
        "forecast = model.predict(future)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tb7CGMxn4bpx",
        "outputId": "b318e0a0-b848-4b66-f736-6b9d5d703bfe"
      },
      "outputs": [],
      "source": [
        "#3\n",
        "#Se grafican las predicciones y componentes del modelo prophet\n",
        "fig_predict = model.plot(forecast)\n",
        "ax_predict = fig_predict.gca()\n",
        "ax_predict.set_title(\"Predicci√≥n del consumo de energ√≠a\")\n",
        "ax_predict.set_xlabel(\"Fecha\")\n",
        "ax_predict.set_ylabel(\"Consumo de Energ√≠a (kWh)\")\n",
        "\n",
        "fig_components = model.plot_components(forecast)\n",
        "for ax in fig_components.axes:\n",
        "    ax.set_xlabel(\"Fecha\")\n",
        "    if ax.get_ylabel() == \"trend\":\n",
        "        ax.set_ylabel(\"Tendencia\")\n",
        "    elif ax.get_ylabel() == \"yearly\":\n",
        "        ax.set_ylabel(\"Estacionalidad Anual\")\n",
        "    elif ax.get_ylabel() == \"weekly\":\n",
        "        ax.set_ylabel(\"Estacionalidad Semanal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gexGftK39Sn6",
        "outputId": "1407528b-6d55-4a9c-b096-d0956c09a6be"
      },
      "outputs": [],
      "source": [
        "#4\n",
        "#Calcule el MAE de la predicci√≥n en el conjunto de entrenamiento y de prueba.\n",
        "mae_train_prophet = mean_absolute_error(train_df_prophet['y'], model.predict(train_df_prophet)['yhat'])\n",
        "mae_test_prophet = mean_absolute_error(test_df_prophet['y'], forecast['yhat'])\n",
        "print(f\"MAE en el conjunto de entrenamiento: {mae_train_prophet}\")\n",
        "print(f\"MAE en el conjunto de prueba: {mae_test_prophet}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ArSXFNJu_QWT",
        "outputId": "b56e96b0-09e0-42c8-ba75-5b2181483aee"
      },
      "outputs": [],
      "source": [
        "#5\n",
        "#Se grafica el error (Valor real - Valor predicho) en todo el intervalo de tiempo.\n",
        "error_prophet = df_energy_prophet['y'] - model.predict(df_energy_prophet)['yhat']\n",
        "fig = px.line(df_energy_prophet, x='ds', y=error_prophet, title='Error de Prophet')\n",
        "fig.update_layout(xaxis_title='Fecha', yaxis_title='Error')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25WNArgLuogS"
      },
      "source": [
        "Se puede observar que se mantienen la estacionalidad de la serie durante los meses de invierno, pero presentandose una menor varianza en los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmv6O8Qj44Dt"
      },
      "source": [
        "## 1.4 Incluyendo Regresores [5 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvWzqXrwRSkc"
      },
      "source": [
        "<center>\n",
        "<img src =\"https://i.redd.it/64hwjftunjjd1.gif\" width = 400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUNihwodPwBG"
      },
      "source": [
        "Con los nuevos resultados obtenidos del modelo Prophet, usted le aconseja a Homero que puede mejorar sus predicciones al incluir regresores en el modelo, es decir, variables adicionales que pueden influir en la variable objetivo, en este caso, el consumo energ√©tico. Homero encuentra que es una buena idea y va en busca de ayuda donde el Profesor Frink, un destacado Cient√≠fico de Springfield. Para suerte de Homero, Frink ten√≠a un estudio reciente que registra las condiciones clim√°ticas en Springfield, en el mismo intervalo de tiempo en que Homero dispon√≠a de los datos de consumo el√©ctrico. Con esta nueva informaci√≥n, usted le recomienda a Homero que podr√≠an utilizar esta informaci√≥n meteorol√≥gica proporcionada como variables ex√≥genas al modelo.\n",
        "\n",
        "Sin embargo, al no comprender bien la importancia de los regresores, Homero decide confiar en sus capacidades y le pide que, por favor, incluya estas variables en el modelo para evaluar su impacto en las predicciones.\n",
        "\n",
        "Para ello, usted debe:\n",
        "0. Seleccionar las variables ex√≥genas a utilizar del archivo `datos_frink.csv`. A√±ada estas variables a sus conjuntos de entrenamiento y prueba mediante `merge`. [0 puntos]\n",
        "1. Cree el modelo Prophet e incluya los regresores (variables ex√≥genas) al modelo. Luego realice el entrenamiento. **Hint**: Utilice el m√©todo `.add_regressor()`. Mas informaci√≥n en el siguiente [Enlace](https://facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html#additional-regressors). [2 puntos]\n",
        "2. Grafique las predicciones y las componentes del modelo Prophet. `Nota`: Utilice los m√©todos `.plot()` y `.plot_components()` de Prophet. [1 punto]\n",
        "3. Calcule el `MAE` de la predicci√≥n en el conjunto de entrenamiento y de prueba. Analice sus resultados. [1 punto]\n",
        "4. Grafique el error (Valor real - Valor predicho) en el conjunto de entrenamiento y de prueba. ¬øHay un comportamiento estacional en la serie? ¬øInfluyen estas variables en el comportamiento del consumo energ√©tico en el hogar de Homero? [1 punto]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BTXeJvXqesW"
      },
      "source": [
        "Los datos del dataset de Frink son los siguientes:\n",
        "\n",
        "* **date**: Fecha de medici√≥n.\n",
        "* **Temp_max**: Temperatura m√°xima registrada durante el d√≠a (en ¬∞F).\n",
        "* **Temp_avg**: Temperatura promedio registrada durante el d√≠a (en ¬∞F).\n",
        "* **Temp_min**: Temperatura m√≠nima registrada durante el d√≠a (en ¬∞F).\n",
        "* **Dew_max**: Punto de roc√≠o m√°ximo registrado durante el d√≠a (en ¬∞F).\n",
        "* **Dew_avg**: Punto de roc√≠o promedio registrado durante el d√≠a (en ¬∞F).\n",
        "* **Dew_min**: Punto de roc√≠o m√≠nimo registrado durante el d√≠a (en ¬∞F).\n",
        "* **Hum_max**: Humedad m√°xima registrada durante el d√≠a (en porcentaje).\n",
        "* **Hum_avg**: Humedad promedio registrada durante el d√≠a (en porcentaje).\n",
        "* **Hum_min**: Humedad m√≠nima registrada durante el d√≠a (en porcentaje).\n",
        "* **Wind_max**: Velocidad m√°xima del viento registrada durante el d√≠a (en millas por hora, mph).\n",
        "* **Wind_avg**: Velocidad promedio del viento registrada durante el d√≠a (en millas por hora, mph).\n",
        "* **Wind_min**: Velocidad m√≠nima del viento registrada durante el d√≠a (en millas por hora, mph).\n",
        "* **Press_max**: Presi√≥n atmosf√©rica m√°xima registrada durante el d√≠a (en pulgadas de mercurio, Hg).\n",
        "* **Press_avg**: Presi√≥n atmosf√©rica promedio registrada durante el d√≠a (en pulgadas de mercurio, Hg).\n",
        "* **Press_min**: Presi√≥n atmosf√©rica m√≠nima registrada durante el d√≠a (en pulgadas de mercurio, Hg)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctwtNdYiSYkt"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sIkCy2vNSZ0N"
      },
      "outputs": [],
      "source": [
        "#0\n",
        "#Se cargan los datos del dataset de Frink\n",
        "cvs_frink = path + '/datos_frink.csv'\n",
        "df_frink = pd.read_csv(cvs_frink)\n",
        "\n",
        "#Se transforma la columna date a formato datetime\n",
        "df_frink['date'] = pd.to_datetime(df_frink['date'])\n",
        "\n",
        "#Se unen a trav√©s de merge a los datos de prueba y entrenamiento\n",
        "df_energy_frink = df_energy.merge(df_frink, on='date', how='left')\n",
        "\n",
        "#Se ajustan los datos para prophet\n",
        "df_energy_frink_prophet = df_energy_frink.rename(columns={'date': 'ds', 'Energy_kWh': 'y'})\n",
        "train_df_frink_prophet = df_energy_frink_prophet[df_energy_frink_prophet['ds'] <= '2020-02-29']\n",
        "test_df_frink_prophet = df_energy_frink_prophet[df_energy_frink_prophet['ds'] >= '2020-03-01']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "O_VHR_ZSvWjx",
        "outputId": "6025480c-2eb1-4cca-c5cf-b4177cd727f0"
      },
      "outputs": [],
      "source": [
        "#1\n",
        "#Para seleccionar las variables exogenas se utilizar√° la correlaci√≥n que presenten las variables\n",
        "correlacion = df_energy_frink_prophet.corr()\n",
        "correlacion.style.background_gradient(cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPFjFiOlnOO-",
        "outputId": "bc38bdd1-4dfe-46ae-b1c8-1fbccd5d759b"
      },
      "outputs": [],
      "source": [
        "#Se crea el modelo Prophet e incluya los regresores al modelo. Hint: Utilice el m√©todo .add_regressor().\n",
        "model_frink = Prophet()\n",
        "var_exogenas = ['Temp_min','Temp_avg','Temp_max','Dew_min','Dew_avg','Dew_max']\n",
        "for var in var_exogenas:\n",
        "  model_frink.add_regressor(var)\n",
        "model_frink.fit(train_df_frink_prophet)\n",
        "\n",
        "#Se realiza el entrenamiento.\n",
        "future_frink = test_df_frink_prophet[['ds', 'Temp_min','Temp_avg','Temp_max','Dew_min','Dew_avg','Dew_max']]\n",
        "forecast_frink = model_frink.predict(future_frink)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Yua3QwXV-3c_",
        "outputId": "bc93575b-c209-4164-fa7c-cde3f4869bf2"
      },
      "outputs": [],
      "source": [
        "#2\n",
        "#Se grafican las predicciones y componentes del modelo\n",
        "fig_predict_frink = model_frink.plot(forecast_frink)\n",
        "ax_predict_frink = fig_predict_frink.gca()\n",
        "ax_predict_frink.set_title(\"Predicci√≥n del consumo de energ√≠a\")\n",
        "ax_predict_frink.set_xlabel(\"Fecha\")\n",
        "ax_predict_frink.set_ylabel(\"Consumo de Energ√≠a (kWh)\")\n",
        "\n",
        "fig_components_frink = model_frink.plot_components(forecast_frink)\n",
        "for ax in fig_components_frink.axes:\n",
        "    ax.set_xlabel(\"Fecha\")\n",
        "    if ax.get_ylabel() == \"trend\":\n",
        "      ax.set_ylabel(\"Tendencia\")\n",
        "    elif ax.get_ylabel() == \"yearly\":\n",
        "        ax.set_ylabel(\"Estacionalidad Anual\")\n",
        "    elif ax.get_ylabel() == \"weekly\":\n",
        "        ax.set_ylabel(\"Estacionalidad Semanal\")\n",
        "    elif ax.get_ylabel() == \"extra_regressors_additive\":\n",
        "        ax.set_ylabel(\"Efecto de Regresores Adicionales\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfJg1WOKEZAb",
        "outputId": "583eac95-10e6-4f66-b359-7163d75b3047"
      },
      "outputs": [],
      "source": [
        "#3\n",
        "#Se calcula el MAE de la predicci√≥n en el conjunto de entrenamiento y de prueba.\n",
        "mae_train_frink = mean_absolute_error(train_df_frink_prophet['y'], model_frink.predict(train_df_frink_prophet)['yhat'])\n",
        "mae_test_frink = mean_absolute_error(test_df_frink_prophet['y'], forecast_frink['yhat'])\n",
        "print(f\"MAE en el conjunto de entrenamiento: {mae_train_frink}\")\n",
        "print(f\"MAE en el conjunto de prueba: {mae_test_frink}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5Uj2jfJEqUG"
      },
      "source": [
        "*Introduzca su respuesta aqu√≠*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "zaFnKZ-nEuPY",
        "outputId": "980bb0e2-3235-4456-d32e-2bfa86858da0"
      },
      "outputs": [],
      "source": [
        "#4\n",
        "#Se separan los valores de train y test por una etiqueta nueva en el df base\n",
        "fecha_separacion = pd.to_datetime('2020-02-29')\n",
        "df_energy_frink_prophet_traintest = df_energy_frink_prophet.copy()\n",
        "df_energy_frink_prophet_traintest['train_test'] = df_energy_frink_prophet_traintest['ds'].apply(lambda x: 'train' if x <= fecha_separacion else 'test')\n",
        "#Se grafica el error (Valor real - Valor predicho) en el conjunto de entrenamiento y de prueba.\n",
        "error_frink_prophet = df_energy_frink_prophet_traintest['y'] - model_frink.predict(df_energy_frink_prophet_traintest)['yhat']\n",
        "fig = px.line(df_energy_frink_prophet_traintest, x='ds', y=error_frink_prophet, color='train_test', title='Error de Prophet')\n",
        "fig.update_layout(xaxis_title='Fecha', yaxis_title='Error')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW8PtPUYFHvV"
      },
      "source": [
        "Se puede observar estacionalidad en la serie de igual manera que en los gr√°ficos anteriores, pero se ve una mejora en la varianza presente en los datos. Esto se asume que se debe a los regresores implementados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF6GHPP89yPk"
      },
      "source": [
        "## 1.5 Aplicando Lags [7 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkRSC7IvL9hT"
      },
      "source": [
        "<center>\n",
        "<img src =\"https://i.gifer.com/J45h.gif\" width = 400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLhDwh6295N-"
      },
      "source": [
        "Homero, satisfecho con los resultados obtenidos, cree que a√∫n puede mejorar el rendimiento del modelo incorporando lags de las variables ex√≥genas. Se le ocurre que, al incluir estos lags, podr√≠a identificar c√≥mo los valores pasados de las variables influyen en la evoluci√≥n de la variable objetivo. Con esta idea en mente, Homero solicita su ayuda para encontrar y aplicar los lags adecuados a las variables ex√≥genas de manera efectiva.\n",
        "\n",
        "Para ello, a usted se le pide que:\n",
        "\n",
        "1. Calcule la `Autocorrelaci√≥n Parcial` de las variables ex√≥genas `avg` que usted haya considerado. Por ejemplo: `Temp_avg, Dew_avg, etc`. Luego determine la cantidad de rezagos (lags) que se va a aplicar a cada una de las variables. Justifique. [1 punto]\n",
        "\n",
        "2. Aplique los lags determinados en el paso anterior e incluyalos como variables en los conjuntos train y test. [1 punto]\n",
        "\n",
        "3. Impute los valores nulos de los nuevos atributos lags mediante la media de cada variable. [1 punto]\n",
        "\n",
        "4. Cree y entrene el modelo Prophet e incluya las variables ex√≥genas y adicionalmente sus respectivos lags al modelo. [1 punto]\n",
        "\n",
        "5. Grafique las predicciones y las componentes del modelo Prophet. `Nota`: Utilice los m√©todos `.plot()` y `.plot_components()` de Prophet. [1 punto]\n",
        "6. Calcule el `MAE` de la predicci√≥n en el conjunto de prueba y en el de entrenamiento. Analice sus resultados. [1 punto]\n",
        "7. Grafique el error (Valor real - Valor predicho) en el conjunto de entrenamiento y en el de prueba. ¬øHay un comportamiento estacional en la serie? ¬øComo afecta la inclusi√≥n de los lags en el desempe√±o del modelo? [1 punto]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ER9nRljShWz"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AiTxiiUnSizV",
        "outputId": "d80c45e3-8d14-4ae8-80f8-33a761e92284"
      },
      "outputs": [],
      "source": [
        "#1\n",
        "#Se calcula la autocorrelaci√≥n parcial de cada variable avg elegida\n",
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "for var in ['Temp_avg', 'Dew_avg']:\n",
        "  fig, ax = plt.subplots(figsize=(12, 6))\n",
        "  plot_pacf(df_energy_frink_prophet[var], lags=90, alpha = 0.05, ax = ax)\n",
        "  plt.title('Partial Autocorrelation Function ' + var)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rylovcgKU3Tp"
      },
      "source": [
        "*Inserte su respuesta aqu√≠*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4xek6SM1U5sA"
      },
      "outputs": [],
      "source": [
        "#2\n",
        "#Se aplican los lags determinados en el paso anterior y se incluyen como variables en los conjuntos train y test.\n",
        "df_energy_frink_prophet_lag = df_energy_frink_prophet.copy()\n",
        "df_energy_frink_prophet_lag['Temp_avg_lag'] = df_energy_frink_prophet_lag['Temp_avg'].shift(4)\n",
        "df_energy_frink_prophet_lag['Dew_avg_lag'] = df_energy_frink_prophet_lag['Dew_avg'].shift(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VU3ziqm5VO7X"
      },
      "outputs": [],
      "source": [
        "#3\n",
        "#Se imputan los valores nulos de los nuevos atributos lags mediante la media de cada variable.\n",
        "df_energy_frink_prophet_lag['Temp_avg_lag'] = df_energy_frink_prophet_lag['Temp_avg_lag'].fillna(df_energy_frink_prophet_lag['Temp_avg_lag'].mean())\n",
        "df_energy_frink_prophet_lag['Dew_avg_lag'] = df_energy_frink_prophet_lag['Dew_avg_lag'].fillna(df_energy_frink_prophet_lag['Dew_avg_lag'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM8KoJsBc5sA",
        "outputId": "e001f2e0-3e8f-4234-c356-e72837114ec1"
      },
      "outputs": [],
      "source": [
        "#4\n",
        "#Se crean los conjuntos de entrenamiento y testeo\n",
        "train_df_frink_prophet_lag = df_energy_frink_prophet_lag[df_energy_frink_prophet_lag['ds'] <= '2020-02-29']\n",
        "test_df_frink_prophet_lag = df_energy_frink_prophet_lag[df_energy_frink_prophet_lag['ds'] >= '2020-03-01']\n",
        "\n",
        "#Se crea el modelo prophet y se entrena con los regresores m√°s los lags\n",
        "model_frink_lag = Prophet()\n",
        "for var in var_exogenas:\n",
        "  model_frink_lag.add_regressor(var)\n",
        "#Se agregan los lags\n",
        "model_frink_lag.add_regressor('Temp_avg_lag')\n",
        "model_frink_lag.add_regressor('Dew_avg_lag')\n",
        "model_frink_lag.fit(train_df_frink_prophet_lag)\n",
        "\n",
        "#Se realiza el entrenamiento.\n",
        "future_frink_lag = test_df_frink_prophet_lag[['ds', 'Temp_min','Temp_avg','Temp_max','Dew_min','Dew_avg','Dew_max','Temp_avg_lag','Dew_avg_lag']]\n",
        "forecast_frink_lag = model_frink_lag.predict(future_frink_lag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b5c0BhqKlqMa",
        "outputId": "c5f1b582-3d02-4f1f-daf5-58f5dd2f1574"
      },
      "outputs": [],
      "source": [
        "#5\n",
        "#Se grafican las predicciones y componentes del modelo\n",
        "fig_predict_frink_lag = model_frink_lag.plot(forecast_frink_lag)\n",
        "ax_predict_frink_lag = fig_predict_frink_lag.gca()\n",
        "ax_predict_frink_lag.set_title(\"Predicci√≥n del consumo de energ√≠a\")\n",
        "ax_predict_frink_lag.set_xlabel(\"Fecha\")\n",
        "ax_predict_frink_lag.set_ylabel(\"Consumo de Energ√≠a (kWh)\")\n",
        "\n",
        "fig_components_frink_lag = model_frink_lag.plot_components(forecast_frink_lag)\n",
        "for ax in fig_components_frink_lag.axes:\n",
        "    ax.set_xlabel(\"Fecha\")\n",
        "    if ax.get_ylabel() == \"trend\":\n",
        "      ax.set_ylabel(\"Tendencia\")\n",
        "    elif ax.get_ylabel() == \"yearly\":\n",
        "        ax.set_ylabel(\"Estacionalidad Anual\")\n",
        "    elif ax.get_ylabel() == \"weekly\":\n",
        "        ax.set_ylabel(\"Estacionalidad Semanal\")\n",
        "    elif ax.get_ylabel() == \"extra_regressors_additive\":\n",
        "        ax.set_ylabel(\"Efecto de Regresores Adicionales\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6CvBLHdl-xz",
        "outputId": "24f8b718-79d3-4daa-8551-227ac39f6b34"
      },
      "outputs": [],
      "source": [
        "#6\n",
        "#Se calcula el MAE de la predicci√≥n en el conjunto de entrenamiento y de prueba.\n",
        "mae_train_frink_lag = mean_absolute_error(train_df_frink_prophet_lag['y'], model_frink_lag.predict(train_df_frink_prophet_lag)['yhat'])\n",
        "mae_test_frink_lag = mean_absolute_error(test_df_frink_prophet_lag['y'], forecast_frink_lag['yhat'])\n",
        "print(f\"MAE en el conjunto de entrenamiento: {mae_train_frink_lag}\")\n",
        "print(f\"MAE en el conjunto de prueba: {mae_test_frink_lag}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "EeqNNVzsmOrX",
        "outputId": "1c9669ae-8260-4476-902a-777aa4902a26"
      },
      "outputs": [],
      "source": [
        "#7\n",
        "#Se separan los valores de train y test por una etiqueta nueva en el df base\n",
        "fecha_separacion = pd.to_datetime('2020-02-29')\n",
        "df_energy_frink_prophet_lag = pd.concat([train_df_frink_prophet_lag, test_df_frink_prophet_lag])\n",
        "df_energy_frink_prophet_lag['train_test'] = df_energy_frink_prophet_lag['ds'].apply(lambda x: 'train' if x <= fecha_separacion else 'test')\n",
        "#Se grafica el error (Valor real - Valor predicho) en el conjunto de entrenamiento y de prueba.\n",
        "error_frink_prophet_lag = df_energy_frink_prophet_lag['y'] - model_frink_lag.predict(df_energy_frink_prophet_lag)['yhat']\n",
        "fig = px.line(df_energy_frink_prophet_lag, x='ds', y=error_frink_prophet_lag, color='train_test', title='Error de Prophet')\n",
        "fig.update_layout(xaxis_title='Fecha', yaxis_title='Error')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbPKQyrarAd-"
      },
      "source": [
        "Se puede observar que hubo una leve mejora al utilizar lags en el conjunto de entrenamiento pero un leve empeoramiento en el conjunto de prueba, manteniendo la estacionalidad general del error presentado. En aspectos generales el uso de variables con lag no afecta en gran medida el comportamiento del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX7JgdOEyTEA"
      },
      "source": [
        "## 1.6 Optimizando Prophet [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXi5MIk3RtgS"
      },
      "source": [
        "<center>\n",
        "<img src =\"https://i.gifer.com/BKlg.gif\" width = 500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYc8t5ukRx1x"
      },
      "source": [
        "Homero, contento con sus resultados, decide compartir su trabajo en LinkedIn. Sin embargo, justo antes de realizar la publicaci√≥n, su hija Lisa Simpson le comenta que su modelo podr√≠a mejorar a√∫n m√°s mediante la optimizaci√≥n de hiperpar√°metros. Aunque Homero no entiende muy bien a qu√© se refiere Lisa, decide confiar en su conocimiento y le pide ayuda para implementar la optimizaci√≥n.\n",
        "\n",
        "Lisa le prepara una funci√≥n llamada optimize_prophet, que recibe como entrada el registro hist√≥rico, los datos a predecir (futuros), el nombre de las variables ex√≥genas y una grilla de hiperpar√°metros que se desea modificar.\n",
        "\n",
        "Despu√©s de varios intentos, Homero no logra utilizar la funci√≥n de Lisa y, desesperado por publicar sus resultados en internet, se acerca a usted en busca de ayuda.\n",
        "\n",
        "Para ello, usted decide realizar los siguientes pasos:\n",
        "\n",
        "1. Crear una grilla donde se modifiquen los siguientes hiperpar√°metros: `changepoint_prior_scale`, `seasonality_prior_scale`, `seasonality_mode`, `changepoint_range` y encuentre los hiperpar√°metros que optimicen el `MAE`. `Nota:` Utilice la funci√≥n `optimize_prophet()` dada en el enunciado. [1 punto]\n",
        "2. Crear y entrenar un modelo Prophet utilizando los mejores par√°metros encontrados, incluyendo regresores (variables ex√≥genas). [2 puntos]\n",
        "3. Grafique las predicciones y las componentes del modelo Prophet. `Nota`: Utilice los m√©todos `.plot()` y `.plot_components()` de Prophet. [1 punto]\n",
        "4. Calcule el `MAE` de la predicci√≥n en el conjunto de entrenamiento y en el de prueba. [1 punto]\n",
        "5. Grafique el error (Valor real - Valor predicho) en ambos conjuntos. Analice sus resultados. [1 punto]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "49jB4USI5B4P"
      },
      "outputs": [],
      "source": [
        "#NO MODIFICAR ESTA CELDA\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "\n",
        "# Silenciar el logging de Prophet\n",
        "logging.getLogger('prophet').setLevel(logging.ERROR)\n",
        "logging.getLogger('cmdstanpy').setLevel(logging.ERROR)\n",
        "\n",
        "\n",
        "def optimize_prophet(df, df_to_pred, features, param_grid ):\n",
        "  '''\n",
        "  Funci√≥n que recibe como entrada:\n",
        "  -df: data entrenamiento.\n",
        "  -df_to_pred: data a predecir (test).\n",
        "  -features: lista de variables ex√≥genas.\n",
        "  -param_grid: grilla de hiperpar√°metros.\n",
        "\n",
        "  Retorna:\n",
        "  -tuning_results: Dataframe con resultados de la optimizaci√≥n.\n",
        "  -best_params: Diccionario de mejores par√°metros encontrados.\n",
        "  '''\n",
        "\n",
        "  # Generate all combinations of parameters\n",
        "  all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
        "  MAEs = []  # Store the MAEs for each params here\n",
        "\n",
        "  # Use tqdm to add a progress bar to the parameter tuning loop\n",
        "  for params in tqdm(all_params, desc=\"Tuning Prophet parameters\"):\n",
        "      m = Prophet(**params)  # Fit model with given params\n",
        "      for feature in features:\n",
        "          m.add_regressor(feature)\n",
        "      m.fit(df)\n",
        "\n",
        "      # Prepare future dataframe\n",
        "      df_prop = m.make_future_dataframe(periods=len(df_to_pred))\n",
        "      df_feat = pd.concat([df[features], df_to_pred[features]]).reset_index(drop=True)\n",
        "      df_prop[features] = df_feat[features]\n",
        "\n",
        "      # Make predictions\n",
        "      forecast = m.predict(df_prop)\n",
        "      forecast_pred = forecast[forecast['ds'].isin(df_to_pred['ds'])].reset_index(drop=True)\n",
        "\n",
        "      # Calculate MAE for the predictions\n",
        "      mae_pred = mean_absolute_error(df_to_pred['y'], forecast_pred['yhat'])\n",
        "      MAEs.append(mae_pred)\n",
        "\n",
        "  # Find the best parameters\n",
        "  tuning_results = pd.DataFrame(all_params)\n",
        "  tuning_results['MAEs'] = MAEs\n",
        "  tuning_results = tuning_results.sort_values(by='MAEs', ascending=True)\n",
        "  best_params = all_params[np.argmin(MAEs)]\n",
        "  return tuning_results, best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XQVCm2VStle"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NCs9MMySSvcg",
        "outputId": "67dafd0e-e410-449c-9045-741f89fc4c55"
      },
      "outputs": [],
      "source": [
        "#1\n",
        "#Creamos los conjuntos de entrenamiento y de testeo para esta secci√≥n\n",
        "train_df_frink_prophet_opt = train_df_frink_prophet.copy()\n",
        "test_df_frink_prophet_opt = test_df_frink_prophet.copy()\n",
        "\n",
        "#Buscamos los mejores hiperpar√°metros para el modelo\n",
        "grilla = {'changepoint_prior_scale' : [1, 0.1, 0.001], 'seasonality_prior_scale': [0.1, 1, 10],\n",
        "          'seasonality_mode' :['additive', 'multiplicative'], 'changepoint_range': [0.8, 0.85, 0.9]}\n",
        "tuning_results, best_params = optimize_prophet(train_df_frink_prophet_opt,test_df_frink_prophet_opt,var_exogenas,grilla)\n",
        "print(tuning_results)\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gQJxuhMJR7MR"
      },
      "outputs": [],
      "source": [
        "#2\n",
        "#Se crea y entrena el modelo prophet con los mejores par√°metros encontrados\n",
        "model_frink_opt = Prophet(**best_params)\n",
        "for var in var_exogenas:\n",
        "  model_frink_opt.add_regressor(var)\n",
        "\n",
        "model_frink_opt.fit(train_df_frink_prophet_opt)\n",
        "future_frink_opt = test_df_frink_prophet_opt[['ds', 'Temp_min','Temp_avg','Temp_max','Dew_min','Dew_avg','Dew_max']]\n",
        "forecast_frink_opt = model_frink_opt.predict(future_frink_opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rIAQ0hm1zNo7",
        "outputId": "b5c6aef9-aeac-4d65-e8a7-c68157effa90"
      },
      "outputs": [],
      "source": [
        "#3\n",
        "#Se grafican las predicciones y componentes del modelo\n",
        "fig_predict_frink_opt = model_frink_opt.plot(forecast_frink_opt)\n",
        "ax_predict_frink_opt = fig_predict_frink_opt.gca()\n",
        "ax_predict_frink_opt.set_title(\"Predicci√≥n del consumo de energ√≠a\")\n",
        "ax_predict_frink_opt.set_xlabel(\"Fecha\")\n",
        "ax_predict_frink_opt.set_ylabel(\"Consumo de Energ√≠a (kWh)\")\n",
        "\n",
        "fig_components_frink_opt = model_frink_opt.plot_components(forecast_frink_opt)\n",
        "for ax in fig_components_frink_opt.axes:\n",
        "    ax.set_xlabel(\"Fecha\")\n",
        "    if ax.get_ylabel() == \"trend\":\n",
        "      ax.set_ylabel(\"Tendencia\")\n",
        "    elif ax.get_ylabel() == \"yearly\":\n",
        "        ax.set_ylabel(\"Estacionalidad Anual\")\n",
        "    elif ax.get_ylabel() == \"weekly\":\n",
        "        ax.set_ylabel(\"Estacionalidad Semanal\")\n",
        "    elif ax.get_ylabel() == \"extra_regressors_additive\":\n",
        "        ax.set_ylabel(\"Efecto de Regresores Adicionales\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXnSeNuMzlQ0",
        "outputId": "c5761db2-0e07-4101-c770-237df4ed690b"
      },
      "outputs": [],
      "source": [
        "#4\n",
        "#Se calcula el MAE de la predicci√≥n en el conjunto de entrenamiento y de prueba.\n",
        "mae_train_frink_opt = mean_absolute_error(train_df_frink_prophet_opt['y'], model_frink_opt.predict(train_df_frink_prophet_opt)['yhat'])\n",
        "mae_test_frink_opt = mean_absolute_error(test_df_frink_prophet_opt['y'], forecast_frink_opt['yhat'])\n",
        "print(f\"MAE en el conjunto de entrenamiento: {mae_train_frink_opt}\")\n",
        "print(f\"MAE en el conjunto de prueba: {mae_test_frink_opt}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "m8WMovTWzwYu",
        "outputId": "5a96c281-d1e6-41bf-fe7d-8834e4a0105d"
      },
      "outputs": [],
      "source": [
        "#5\n",
        "#Se separan los valores de train y test por una etiqueta nueva en el df base\n",
        "fecha_separacion = pd.to_datetime('2020-02-29')\n",
        "df_energy_frink_prophet_opt = pd.concat([train_df_frink_prophet_opt, test_df_frink_prophet_opt])\n",
        "df_energy_frink_prophet_opt['train_test'] = df_energy_frink_prophet_opt['ds'].apply(lambda x: 'train' if x <= fecha_separacion else 'test')\n",
        "#Se grafica el error (Valor real - Valor predicho) en el conjunto de entrenamiento y de prueba.\n",
        "error_frink_prophet_opt = df_energy_frink_prophet_opt['y'] - model_frink_opt.predict(df_energy_frink_prophet_opt)['yhat']\n",
        "fig = px.line(df_energy_frink_prophet_opt, x='ds', y=error_frink_prophet_opt, color='train_test', title='Error de Prophet')\n",
        "fig.update_layout(xaxis_title='Fecha', yaxis_title='Error')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKiNhw020-xE"
      },
      "source": [
        "Como se puede observar en el gr√°fico y en los valores del MAE, utilizando los mejores par√°metros se obtuvieron mejores resultados, disminuyendo el MAE tanto para el conjunto de entrenamiento como para el de testeo, adem√°s se puede observar un gr√°fico m√°s homog√©neo que los anteriores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVox6yBNCS6T"
      },
      "source": [
        "# **2. Sistemas de Recomendaci√≥n (30 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKtN95WQCjcp"
      },
      "source": [
        "## Homero contra la Prohibici√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD7xVTFp4rac"
      },
      "source": [
        "<center>\n",
        "<img src =\"https://i.ytimg.com/vi/rMSXXuhZjYY/maxresdefault.jpg\" width = 500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrf2l5Xb1xd7"
      },
      "source": [
        "En Springfield, el caos estall√≥ cuando las autoridades prohibieron el alcohol. Pero como siempre, donde otros ven problemas, Homero Simpson ve oportunidades. Decidido a mantener las fiestas vivas, se convirti√≥ en el Bar√≥n de la Cerveza en un abrir y cerrar de ojos. Con la ayuda de su buen amigo Moe el cantinero, Homero obtuvo un valioso dataset llamado `cervezas.csv`, que contiene valoraciones de los ciudadanos de Springfield sobre distintas cervezas. Homero quiere asegurarse de ofrecer las cervezas m√°s apreciadas para mantener a su clientela oculta y feliz, mientras elud√≠a la mirada del estricto Elio Pez. Por ende, Homero lo contacta para solicitar de su ayuda en esta nueva labor.\n",
        "\n",
        "El dataset contiene los siguientes atributos:\n",
        "\n",
        "  * userId: Identificador de los ciudadanos/usuarios\n",
        "  * beerId: Identificador √∫nico de cada cerveza\n",
        "  * rating: Evaluaci√≥n otorgada por el ciudadano a la cerveza, en un rango de 1.0 a 5.0.\n",
        "  * beerName: Nombre de la cerveza\n",
        "  * beerStyle: Tipo de Cerveza.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87A32f0bxjq-",
        "outputId": "ac226114-0af0-43bc-b8c4-344aa5ca6b4e"
      },
      "outputs": [],
      "source": [
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm4EO6VRvBLQ"
      },
      "outputs": [],
      "source": [
        "# Librerias extras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from surprise import accuracy\n",
        "from surprise.reader import Reader\n",
        "from surprise.dataset import Dataset\n",
        "from surprise.prediction_algorithms.knns import KNNBasic\n",
        "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
        "from surprise.accuracy import mae\n",
        "from surprise import NMF\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import pandas as pd\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSctqoUm5JLB"
      },
      "source": [
        "## Carga de los datos [0 puntos]\n",
        "\n",
        "Cargue el dataset `cervezas.csv` y realice una breve exploraci√≥n de los datos. ¬øHay valores nulos? ¬øCuantos cervezas se estan evaluando? ¬øCuantos ciudadanos participaron de esta evaluaci√≥n?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5CZSmv0F3Oc"
      },
      "outputs": [],
      "source": [
        "def exploratory_data_analysis(dataframe):\n",
        "  #1. dimension df\n",
        "  print(f\"1. La dimension del dataframe es: {dataframe.shape} \\n\")\n",
        "  #2. nombres de las columnas del df\n",
        "  print(f\"2. Las columnas que conforman el dataframe son: \\n {dataframe.columns} \\n\")\n",
        "  #3. mostrar los primeros 5 elementos, 5 ultimos elementos y 5 elementos aleatoreos\n",
        "  print(\"3.a Los 5 primeros elementos del dataframe son:\")\n",
        "  display(dataframe.head(5))\n",
        "  print(\"3.b Los 5 √∫ltimos elementos del dataframe son:\")\n",
        "  display(dataframe.tail(5))\n",
        "  print(\"3.c 5 elementos al azar del dataframe son:\")\n",
        "  display(dataframe.sample(5, random_state=10))\n",
        "  #4. descripcion rapida de las variables numericas del dataframe\n",
        "  print(f\"4. Descripci√≥n de las variables num√©ricas del dataframe:\")\n",
        "  display(dataframe.describe())\n",
        "  #5. mensaje con la cantidad de valores nulos\n",
        "  print(f\"5. La cantidad de valores nulos en el dataframe son: \\n {dataframe.isna().sum()} \\n\")\n",
        "  #6. mensaje que detalle la cantidad de valores unicos\n",
        "  print(f\"6. La cantidad de valores unicos en el dataframe son: \\n {dataframe.nunique()} \\n\")\n",
        "  #7. mensaje con el total de filas que contengan nombres duplicados\n",
        "  print(f\"7. Total de filas que contienen userId duplicados: {dataframe.duplicated(subset=['userId']).sum()} \\n\")\n",
        "  #8. Mostrar las filas que contengan nombres sean duplicados\n",
        "  print(f\"8. Filas que contienen userId duplicados:\")\n",
        "  display(dataframe[dataframe.duplicated(subset=['userId'])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLPJ2i7vGHpY"
      },
      "outputs": [],
      "source": [
        "#cargamos el dataset\n",
        "cvs_cervezas = path + '/cervezas.csv'\n",
        "df_cervezas = pd.read_csv(cvs_cervezas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Gp5RMLpTTOVD",
        "outputId": "d4fc9eb6-65f8-44e3-aab1-afbe7c614213"
      },
      "outputs": [],
      "source": [
        "#exploramos los datos\n",
        "exploratory_data_analysis(df_cervezas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlX_DgcbHs-t"
      },
      "source": [
        "*analisis exploratorio del dataset*\n",
        "\n",
        "Mediante la exploraci√≥n realizada, no hay valores nulos en el dataset, la cantidad de cervezas que se estan evaluando son 3747 ya que esas es la cantidad de beerId √∫nicos en el dataset.\n",
        "\n",
        "Finalmente la cantidad de ciudadanos que participaron de esta evaluaci√≥n fueron 706 ya que esa es la cantidad de userId √∫nicos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v0xBQmN9v80"
      },
      "source": [
        "## 2.1 Caracterizaci√≥n Inicial [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbsflKIA9zO9"
      },
      "source": [
        "Antes de entrenar nuestro sistema recomendador, es necesario caracterizar los datos disponibles y de esta manera tener un mejor entendimiento del problema a resolver. Para esto, se le pide lo siguiente:\n",
        "\n",
        "1. Genere gr√°ficos y/o estad√≠stica descriptiva con los datos. Utilice su an√°lisis para responder las siguientes preguntas: [2 puntos]\n",
        "  - ¬øCuantos *usuarios* hay en los datos?\n",
        "  - ¬øCuantos *productos* hay en los datos?\n",
        "  - ¬øCuantas *calificaciones* hay en los datos?\n",
        "  - ¬øCuantas *calificaciones* faltantes hay en los datos?\n",
        "  - ¬øCual es la media de las *calificaciones* entregadas por los usuarios? ¬øC√≥mo cambia esto a trav√©s de los productos?  \n",
        "2. Transforme los datos entregados a una matriz (usuario, producto) y muestre sus resultados. [1 punto]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "iI5lBJypInpX",
        "outputId": "9ab37c0c-8799-407a-fa30-e78c862bf9c6"
      },
      "outputs": [],
      "source": [
        "#1. Generar graficos y/o estadisticas descriptiva con los datos\n",
        "#cuantos usuarios hya en los datos\n",
        "print(f\"Cuantos usuarios hay en los datos: {df_cervezas['userId'].nunique()}\")\n",
        "#cuantos productos hay en los datos\n",
        "print(f\"Cuantos productos hay en los datos: {df_cervezas['beerId'].nunique()}\")\n",
        "#cuantas calificaciones hya en los datos\n",
        "print(f\"Cuantas calificaciones hay en los datos: {df_cervezas.shape[0]}\")\n",
        "#cuantas calificaciones faltantes hay en los datos\n",
        "print(f\"Cuantas calificaciones faltantes hay en los datos: {df_cervezas['rating'].isna().sum()}\")\n",
        "#media de las calificaicones entregadas por los usuarios\n",
        "print(f\"Media de las calificaciones entregadas por los usuarios:\")\n",
        "df_cervezas.loc[:, [\"rating\"]].describe().round(4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "rraTepqvikjN",
        "outputId": "86fae6e5-50d0-4f70-a766-b97a0141da7e"
      },
      "outputs": [],
      "source": [
        "px.histogram(\n",
        "    df_cervezas,\n",
        "    x=\"rating\",\n",
        "    title=\"An√°lisis de la variable rating\",\n",
        "    marginal=\"box\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "khX8AlSRJ2Wl",
        "outputId": "54fb8edc-7f9d-4d4e-f4bb-4e264c8f5f6f"
      },
      "outputs": [],
      "source": [
        "#2. Transforme los datos entregados a una matriz(usuario, producto) y muestre sus resultados\n",
        "df_cervezas_pivot = df_cervezas.pivot_table(index='userId', columns='beerId', values='rating', fill_value=0)\n",
        "df_cervezas_pivot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_RHVQbNvGKQ"
      },
      "source": [
        "## 2.2 M√©todo Basado en Contenido [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr2XsjuH6bEm"
      },
      "source": [
        "<center>\n",
        "<img src =\"https://is1-ssl.mzstatic.com/image/thumb/WfNa_TwFpJoTWXQmU-BrbA/1200x675.jpg\" width = 500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rCGuXKI52RJ"
      },
      "source": [
        "Como primera tarea, Homero le pide centrarse en las caracter√≠sticas de las cervezas y no en la interacci√≥n de los ciudadanos con esta. Adicionalmente, Homero le quiere regalar un pack de distintas cervezas a Carl en agradecimiento a su ayuda anterior, el cual se enter√≥ que Carl tiene un `userId = 100`. Por ende, Homero le pide las siguientes acciones:\n",
        "\n",
        "1. Cree un dataframe que contenga las caracter√≠sticas de las cervezas, excluyendo las evaluaciones de los ciudadanos. `Nota:` No considere valores duplicados. [1 punto]\n",
        "2. Implemente el m√©todo Bag of Words para procesar la columna `beerStyle`. Para ello, transforme las palabras a min√∫sculas, elimine stopwords en ingl√©s y filtre las palabras que aparezcan en 10 documentos como m√≠nimo. Guarde su resultado como un DataFrame. [1 punto].\n",
        "> `Nota:` Le puede ser √∫til esta [documentacion](https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) y el m√©todo `.get_feature_names_out()`.\n",
        "3. Cree una funci√≥n que imprima las top 5 cervezas similares a `Chocolate Porter`, utilizando como medida de similitud la similitud coseno. [1 punto]\n",
        "4. Identifique la cerveza mejor evaluada por Homero (`userId = 100`) y obtenga las top 5 cervezas similares a esa cerveza. [1 punto]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cmVF_zATVdq"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv3qlPfrTX9-"
      },
      "outputs": [],
      "source": [
        "#1. Cree un dataframe que contenga las caracter√≠sticas de las cervezas, excluyendo las evaluaciones de los ciudadanos. Nota: No considere valores duplicados\n",
        "df_cervezas_caracteristicas = df_cervezas.drop(columns=['rating'])\n",
        "df_cervezas_caracteristicas = df_cervezas_caracteristicas.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z9mccJ_Zj6Rw",
        "outputId": "9acdd679-fa28-4b32-9cf9-3000e4299c83"
      },
      "outputs": [],
      "source": [
        "#usuario userId=100\n",
        "df_cervezas_caracteristicas[df_cervezas_caracteristicas['userId'] == 100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "KWb3zty9Wrya",
        "outputId": "e4d4b477-a136-4265-a785-7ab678cb2593"
      },
      "outputs": [],
      "source": [
        "#Implemente el m√©todo Bag of Words para procesar la columna beerStyle. Para ello, transforme las palabras a min√∫sculas, elimine stopwords en ingl√©s\n",
        "#y filtre las palabras que aparezcan en 10 documentos como m√≠nimo. Guarde su resultado como un DataFrame.\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(lowercase = True, # transformaci√≥n a min√∫sculas\n",
        "                             min_df = 10, # m√≠nimo 10 ocurrencias\n",
        "                             stop_words = 'english') # eliminar stopwords\n",
        "bow = vectorizer.fit_transform(df_cervezas_caracteristicas['beerStyle']).toarray() # Vectorizamos texto\n",
        "bow = pd.DataFrame(bow, columns=vectorizer.get_feature_names_out(),index=df_cervezas_caracteristicas['beerId']) # Transformamos a Dataframe\n",
        "bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kuCQosZojZi",
        "outputId": "d2481f1b-10c4-4a96-f117-180a0e63ff0a"
      },
      "outputs": [],
      "source": [
        "# importamos cosine_similarity de sklearn\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# calculamos la similitud coseno de cada vector generado contra el resto\n",
        "cosine_sim = cosine_similarity(bow, bow)\n",
        "cosine_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCqsQ03uiJSZ",
        "outputId": "4dc37180-0321-41e1-9825-face89348c43"
      },
      "outputs": [],
      "source": [
        "len(cosine_sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywW02WVPW0ba"
      },
      "outputs": [],
      "source": [
        "#3. Cree una funci√≥n que imprima las top 5 cervezas similares a Chocolate Porter, utilizando como medida de similitud la similitud coseno.\n",
        "def get_recommendations(df, cerveza, k = 5):\n",
        "\n",
        "  \"\"\"\n",
        "  Returns the top k similar cervezas using BoW\n",
        "  \"\"\"\n",
        "\n",
        "  # Assert cerveza is contained in dataset\n",
        "  assert cerveza in df['beerName'].values, 'cerveza is not contained in train dataset!'\n",
        "\n",
        "  # Get idx of movie\n",
        "  idx = df[df['beerName'] == cerveza]['beerId'].values[0]\n",
        "  # print(idx)\n",
        "  idx_bow = bow.index.get_loc(idx)\n",
        "  # print(idx_bow)\n",
        "\n",
        "  # Get pairwise similarities of all cervezas with specified movie\n",
        "  sim_scores = list(enumerate(cosine_sim[idx_bow]))\n",
        "\n",
        "  # Sort the cervezas based on the similarity scores\n",
        "  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  # Get the scores of the k most similar cervezas\n",
        "  sim_scores = sim_scores[1:k+1]\n",
        "\n",
        "  # Get the cerveza indices\n",
        "  cerveza_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "  # Return the top k most similar movies\n",
        "  return df['beerName'].iloc[cerveza_indices].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsDE5K2aonB5",
        "outputId": "6dde427e-8ad4-4949-ebe9-6f8e514a802e"
      },
      "outputs": [],
      "source": [
        "top_5=get_recommendations(df = df_cervezas_caracteristicas, cerveza = 'Chocolate Porter')\n",
        "print(f' top 5 cervezas similares a Chocolate Porter: {top_5}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS4mKrT4W9kb",
        "outputId": "784a6674-ac42-4dbc-eec3-f3fc0b5fced1"
      },
      "outputs": [],
      "source": [
        "#4. Identifique la cerveza mejor evaluada por Carl (userId = 100) y obtenga las top 5 cervezas similares a esa cerveza.\n",
        "# primero rescatamos la cerveza m√°s tomada por el usuario\n",
        "userId = 100 #usuario a recomendar\n",
        "user_cerveza = df_cervezas[df_cervezas['userId'] == userId].sort_values('rating', ascending = False) # cervezas rateadas por el usuario\n",
        "best_cerveza = user_cerveza.iloc[0]['beerName'] # cerveza con mejor rating\n",
        "print(f'most liked cerveza by user {userId}: {best_cerveza}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "r7LwdREFrfhn",
        "outputId": "a37877fb-4461-4171-879c-0aa7ae04615a"
      },
      "outputs": [],
      "source": [
        "df_cervezas_caracteristicas[df_cervezas_caracteristicas['beerName'] == best_cerveza]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz5fpSfeq-1N",
        "outputId": "bd9671fc-59f8-4af6-bbfd-2987cac9092e"
      },
      "outputs": [],
      "source": [
        "top_5_userId=get_recommendations(df = df_cervezas_caracteristicas, cerveza = best_cerveza)\n",
        "print(f'Top 5 de las cervezas m√°s similares a la cerveza most liked for Homero: {top_5_userId}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7pMOOedwGQu"
      },
      "source": [
        "## 2.3 Filtros Colaborativos [16 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9tgPpoa_Utx"
      },
      "source": [
        "<center>\n",
        "<img src =\"https://i.makeagif.com/media/2-08-2016/McmGFQ.gif\" width = 400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJeoHmbQA9uK"
      },
      "source": [
        "Despu√©s de consolidarse como el Bar√≥n de la Cerveza en Springfield, Homero Simpson decidi√≥ llevar su negocio clandestino a otro nivel. Al ser el √∫nico proveedor de alcohol en la ciudad, quiere asegurarse de que cada cerveza que elabora sea de la mejor calidad posible. Para lograrlo, planea usar las evaluaciones pasadas que los ciudadanos de Springfield han registrado sobre las distintas cervezas. Inspirado por los consejos de su amigo Moe, Homero se enter√≥ de que puede implementar un sistema de recomendaci√≥n basado en filtros colaborativos.\n",
        "\n",
        "Ahora, Homero necesita de su ayuda para dise√±ar y elaborar distintos sistemas de filtros colaborativos que le permitan continuar con su reinado cervecero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGCI_UeUwHcw"
      },
      "source": [
        "### 2.3.1 Filtros Colaborativos Basados en Memoria [8 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWnf00k4BdyC"
      },
      "source": [
        "Para este tipo de filtros, Homero le pide lo siguiente:\n",
        "\n",
        "1. Transforme el DataFrame de `pandas` a Dataset de `surprise`. `Hint`: Utilice solamente los identificadores de ciudadano, cerveza y rating. ¬øImporta el orden? [1 punto]\n",
        "2. Genere un conjunto de entrenamiento y uno de prueba, asegurando que el 30% de los datos sea destinado al conjunto de prueba. No olvide fijar una semilla para garantizar reproducibilidad. [1 punto]\n",
        "3. Entrene un modelo de **KNN basado en usuarios** utilizando la `similitud coseno`. Luego realice predicciones en el conjunto de prueba. `Nota`: Le puede ser √∫til la siguiente [documentaci√≥n](https://surprise.readthedocs.io/en/stable/knn_inspired.html) [2 puntos]\n",
        "4. Calcule el MAE (Mean Absolute Error) de las predicciones realizadas por el modelo y muestre las predicciones en un DataFrame para su an√°lisis. `Nota:` Le puede ser √∫til la siguiente [documentaci√≥n](https://surprise.readthedocs.io/en/stable/accuracy.html#surprise.accuracy.mae) [2 puntos]\n",
        "5. Repita los pasos 3 y 4 pero utilizando un modelo de **KNN basado en los productos**. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBAY-wkNTfFu"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuZyXYxAkl6S",
        "outputId": "1ad702d2-999d-4321-ba63-2de87855c79b"
      },
      "outputs": [],
      "source": [
        "df_cervezas['rating'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6GZBM2uTig4"
      },
      "outputs": [],
      "source": [
        "#1. trasnformar el dataframe de pandas a dataset de surprise, usar solo identificadores de ciudadano, cerveza y rating\n",
        "reader = Reader(rating_scale=(0, 5))\n",
        "df_surprise = Dataset.load_from_df(df_cervezas[['userId',  'beerId','rating']], reader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT5m2TaRkt4C"
      },
      "source": [
        "*1. Importa el orden?*\n",
        "\n",
        "Si, el orden en esta ocasi√≥n importa ya que define cual variable se usar√° como usuario, item y valoraci√≥n en el dataset y en ese mismo orden, es por esto que se define el orden de userId, beerId y rating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngRz4Q2QXZLf"
      },
      "outputs": [],
      "source": [
        "#2. Genere un conjunto de entrenamiento y uno de prueba,\n",
        "#asegurando que el 30% de los datos sea destinado al conjunto de prueba.\n",
        "#No olvide fijar una semilla para garantizar reproducibilidad.\n",
        "from surprise.model_selection import train_test_split\n",
        "trainset, testset = train_test_split(df_surprise, test_size=0.3, random_state=3380)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "gBvbvGxQXbau",
        "outputId": "1379df6e-fc98-4215-ba56-0d73f083fbfd"
      },
      "outputs": [],
      "source": [
        "#3.Entrene un modelo de KNN basado en usuarios utilizando la similitud coseno. Luego realice predicciones en el conjunto de prueba\n",
        "from surprise.similarities import cosine\n",
        "model_knn=KNNBasic(sim_options= {'name': 'cosine', 'user_based': True})\n",
        "model_knn.fit(trainset)\n",
        "predictions=model_knn.test(testset)\n",
        "df_predictions = pd.DataFrame(predictions)\n",
        "df_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fhHZgNWk0v6",
        "outputId": "c5d602c4-ad55-4cd8-982c-522b429c4e02"
      },
      "outputs": [],
      "source": [
        "#4. Calcule el MAE (Mean Absolute Error) de las predicciones\n",
        "#realizadas por el modelo y muestre las predicciones en un DataFrame\n",
        "#para su an√°lisis\n",
        "from surprise.accuracy import mae\n",
        "mae(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "2gwL9phHk2fO",
        "outputId": "7fb4a588-8da2-47b2-8449-c61dea5e3628"
      },
      "outputs": [],
      "source": [
        "#5. Repita los pasos 3 y 4 pero utilizando un modelo de KNN\n",
        "#basado en los productos\n",
        "model_knn_products=KNNBasic(sim_options={'name': 'cosine', 'user_based': False})\n",
        "model_knn_products.fit(trainset)\n",
        "predictions_products=model_knn_products.test(testset)\n",
        "df_predictions_products = pd.DataFrame(predictions_products)\n",
        "df_predictions_products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBlk9uk5k38Q",
        "outputId": "9fe79673-f1d6-44c3-9c85-9bf7ae851a33"
      },
      "outputs": [],
      "source": [
        "mae(predictions_products)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhYHlQYowqd_"
      },
      "source": [
        "### 2.3.2 Filtros Colaborativos Basados en Modelo [8 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLRjmyYDGgWq"
      },
      "source": [
        "Ahora Homero le pide que cambie el enfoque del tipo de filtro colaborativo a uno basado en modelo. Por ende, Homero le pide lo siguiente:\n",
        "\n",
        "1. Entrene un modelo `NMF` , asegur√°ndose de fijar la semilla para reproducibilidad. Luego genere predicciones para el conjunto de prueba. [2 puntos]\n",
        "2. Calcule el MAE de las predicciones obtenidas y muestre los resultados de las predicciones en un DataFrame para su analisis. [1 punto]\n",
        "3. Entrene un modelo `SVD` sobre el conjunto de entrenamiento. Posteriormente, genere las predicciones para el conjunto de prueba. [2 puntos]\n",
        "4. Calcule el MAE de las predicciones y muestre los resultados de las predicciones en un DataFrame. [1 punto]\n",
        "5. Compare los resultados de ambos modelos y seleccione el mejor a su criterio. Justifique. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkH_1GJiTk95"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "DpZm03aUTmu-",
        "outputId": "9307a3cb-885f-456f-d085-d920d7e35060"
      },
      "outputs": [],
      "source": [
        "#1. entrene modelo NMF, asegure semilla para reproducibilidad. Genere predicciones conjunto prueba\n",
        "model_nmf = NMF(random_state=3380)\n",
        "model_nmf.fit(trainset)\n",
        "predictions_nmf = model_nmf.test(testset)\n",
        "#2. calcule MAE de las predis obtenidas y muestre results en un dataframe\n",
        "mae(predictions_nmf)\n",
        "df_predictions_nmf = pd.DataFrame(predictions_nmf)\n",
        "df_predictions_nmf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "0FpOuptWk9Nd",
        "outputId": "6da8b443-df8a-483e-814b-5920b5ba1bbc"
      },
      "outputs": [],
      "source": [
        "#3.entrena modelo SVD sobre el conjunto entrenamiento. dsps genere predis en el conjunto de prueba\n",
        "model_svd = SVD()\n",
        "model_svd.fit(trainset)\n",
        "predictions_svd = model_svd.test(testset)\n",
        "#4. calcula mae y lleve a dataframe los results\n",
        "mae(predictions_svd)\n",
        "df_predictions_svd = pd.DataFrame(predictions_svd)\n",
        "df_predictions_svd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZrS_wqblATf"
      },
      "source": [
        "*5. Comparaci√≥n de modelos*\n",
        "\n",
        "De los modelos vistos anteriormente se obtienen MAE's similares entre 0.46 a 0.48, estos son valores bajos indicando que las predicciones del modelo est√°n muy cercanas al valor real. Adem√°s es esperable un valor bajo ya que la variable que se est√° poniendo en juego es rating, la cual no tiene una magnitud grande ya que solo se mueve entre 0 y 5, en cambio si fuera un rango mayor, probablemente el mae aumentar√≠a.\n",
        "\n",
        "Por lo anterior, se escoge como mejor modelo el que posee menor error, es decir menor MAE, el cual es el modelo SVD con un mae=0.4627"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-zlOMPdH5nT"
      },
      "source": [
        "## 2.4 El Mejor Filtro Colaborativo [7 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX4JsISWJ-fS"
      },
      "source": [
        "<center>\n",
        "<img src =\"https://media.giphy.com/media/citBl9yPwnUOs/giphy.gif\" width = 400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOPZ5Q05NZej"
      },
      "source": [
        "Homero Simpson desea perfeccionar y extender su sistema de recomendaciones para cervezas en Springfield. En esta fase, busca implementar t√©cnicas que le permitan no solo predecir las preferencias de los ciudadanos, sino tambi√©n evaluar m√©tricas que midan la eficacia de sus recomendaciones. Con el objetivo de recomendar las mejores K cervezas para usuarios espec√≠ficos, Homero buscar√° comprender mejor c√≥mo optimizar su sistema y satisfacer a sus clientes.\n",
        "\n",
        "Para ello, usted ayudar√° a Homero realizando las siguientes labores:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdUi4etiIDPY"
      },
      "source": [
        "1. Implemente la funci√≥n `get_top_n()` que le permita extraer las `N` mejores cervezas recomendadas para cada ciudadano utilizando las predicciones generadas por el mejor modelo seleccionado en la secci√≥n anterior. Luego obtenga las `3` mejores cervezas recomendadas para Homero (`userId = 100`). `Hint`: Para cada ciudadano, elimine las predicciones duplicadas. [2 puntos]\n",
        "2. Realice predicciones de rating para 5 cervezas aleatorias no evaluadas por Homero, para estimar las calificaciones que Homero podr√≠a darles. [1 punto]\n",
        "3. Calcule los promedios de `precisi√≥n@k` y el `recall@k` para `k=10` y `threshold = 3.5`. Analice sus resultados. ¬øEs un buen modelo? `Hint:` Utilice la funci√≥n dada `precision_recall_at_k(...)`. [1 punto]\n",
        "4. Calcule la `precisi√≥n@k` y el `recall@k` para valores de `k` que var√≠en entre 3 y 25 con paso de 1 unidad. Luego, grafique los resultados y analice el comportamiento de las curvas de precisi√≥n y recall en funci√≥n de `k`. [1 punto]\n",
        "5. Calcule la `precisi√≥n@k` y el `recall@k` para valores de `threshold` que var√≠en entre 3.0 y 4.5, con paso de 0.1. Luego, grafique los resultados y analice el comportamiento de las curvas de precisi√≥n y recall en funci√≥n de `threshold`. [1 punto]\n",
        "6. Finalmente utilice el mejor modelo para estimar los ratings faltantes. Muestre sus resultados en una matriz (usuario, producto) sin valores nulos. [1 punto]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsV3CY1uxRig"
      },
      "outputs": [],
      "source": [
        "#NO MODIFICAR ESTA CELDA\n",
        "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
        "\n",
        "    user_est_true = defaultdict(list)\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "        n_rel_and_rec_k = sum(\n",
        "            ((true_r >= threshold) and (est >= threshold))\n",
        "            for (est, true_r) in user_ratings[:k]\n",
        "        )\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "    return precisions, recalls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUcwX6xfTyGB"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur-Tu9MPT0Gp"
      },
      "outputs": [],
      "source": [
        "#1.implementar get_top_n que permita extraer n mejores cervezas recomendadas para cada ciudadano usando predis por el mejor modelo seleccionado anterior\n",
        "#luego las mejores 3 cervezas recomendadas para homero user=100. Elimine las predis duplicadas\n",
        "from collections import defaultdict\n",
        "\n",
        "def get_top_n(predictions, n=10):\n",
        "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
        "\n",
        "    Args:\n",
        "        predictions(list of Prediction objects): The list of predictions, as\n",
        "            returned by the test method of an algorithm.\n",
        "        n(int): The number of recommendation to output for each user. Default\n",
        "            is 10.\n",
        "\n",
        "    Returns:\n",
        "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
        "        [(raw item id, rating estimation), ...] of size n.\n",
        "    \"\"\"\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        #duplicados de predis\n",
        "        if est not in [x[1] for x in top_n[uid]]:\n",
        "            top_n[uid].append((iid, est))\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg2v52OslJus",
        "outputId": "5856c9e1-14be-4506-afc5-e66e40e369fc"
      },
      "outputs": [],
      "source": [
        "#obtengo las de homero de get top n\n",
        "homero_top_n = get_top_n(predictions_svd, n = 3)\n",
        "homero_top_n.get(100, [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zeWnddwylLak",
        "outputId": "d5eb2d4d-81c1-48b4-d229-281c3e89289c"
      },
      "outputs": [],
      "source": [
        "#2Realice predicciones de rating para 5 cervezas aleatorias no evaluadas por Homero, para estimar las calificaciones que Homero podr√≠a darles\n",
        "import random\n",
        "\n",
        "#Lista de todas las cervezas\n",
        "all_beers = set(df_cervezas['beerId'])\n",
        "\n",
        "#Obtener las cervezas que homero a evaluado\n",
        "evaluadas_por_homero = list(df_cervezas[df_cervezas['userId'] == 100]['beerId'])\n",
        "\n",
        "#Obtener cervezas no evaluadas por homero\n",
        "no_evaluadas_por_homero = list(all_beers - set(evaluadas_por_homero))\n",
        "\n",
        "#5 cervezas aleatorias\n",
        "random_beers = random.sample(no_evaluadas_por_homero, 5)\n",
        "\n",
        "#Predecir el rating para las 5 cervezas seleccionadas\n",
        "pre_random=[]\n",
        "for beer in random_beers:\n",
        "    pre_random.append( model_nmf.predict(100, beer))\n",
        "\n",
        "predi_random = pd.DataFrame(pre_random)\n",
        "predi_random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMQdmDXtlM6O",
        "outputId": "93346695-9d92-4247-c942-efee7c3c8a3f"
      },
      "outputs": [],
      "source": [
        "#3 Calcule los promedios de precisi√≥n@k y el recall@k para k=10 y threshold = 3.5.\n",
        "# Analice sus resultados. ¬øEs un buen modelo? Hint: Utilice la funci√≥n dada precision_recall_at_k(...)\n",
        "precisions, recalls = precision_recall_at_k(predictions_nmf, k=10, threshold=3.5)\n",
        "precision = np.mean([precision for precision in precisions.values()])\n",
        "recall = np.mean([recall for recall in recalls.values()])\n",
        "print(f\"Precisi√≥n@k: {precision:.2f}, Recall@k: {recall:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgR7OLN_oM7B"
      },
      "source": [
        "*3. es un buen modelo?*\n",
        "\n",
        "Un bajo recall nos indica que el modelo captur√≥ pocos casos positivos correctamente, se suele buscar un modelo con recall alto para evitar costos asociados a un falso negativo. Por otro lado en precisi√≥n tiene una alta tasa de predicci√≥n correcta, as√≠ se concluye que el modelo no es bueno ya que posee bajo recall y la idea es tener el mayor recall posible a pesar de que tenga una buena precision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATf9Y4s0lUJB"
      },
      "outputs": [],
      "source": [
        "#4. Calcule la precisi√≥n@k y el recall@k para valores de k que var√≠en entre 3 y 25 con paso de 1 unidad.\n",
        "#Luego, grafique los resultados y analice el comportamiento de las curvas de precisi√≥n y recall en funci√≥n de k\n",
        "r=list(range(3,26))\n",
        "pre=[]\n",
        "recall=[]\n",
        "for i in r:\n",
        "  precisions, recalls = precision_recall_at_k(predictions_nmf, k=i, threshold=3.5)\n",
        "  mean_precision=np.mean([precision for precision in precisions.values()])\n",
        "  mean_recall=np.mean([recall for recall in recalls.values()])\n",
        "  pre.append(mean_precision)\n",
        "  recall.append(mean_recall)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5N4FAbt0lWfh",
        "outputId": "59dac5be-fff5-46ce-aa0f-37fe60e7bcde"
      },
      "outputs": [],
      "source": [
        "#gafico resultados de pre y recall con plotly\n",
        "#grafico precision\n",
        "fig = px.line(x=r, y=pre, title='Gr√°fico Precisi√≥n@k')\n",
        "fig.show()\n",
        "#grafico recall\n",
        "fig = px.line(x=r, y=recall, title='Gr√°fico Recall@k')\n",
        "fig.show()\n",
        "#grafio PR\n",
        "fig = px.line(x=recall, y=pre, title='Grpafico PR')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC4aOKdCVZ6z"
      },
      "source": [
        "*Comentario*\n",
        "\n",
        "En lo gr√°ficos se puede observar que a medida que el k aumenta tambien lo hace el recall, en cambio el precision baja. Lo anterior se puede deber a que varia la cantidad de datos.\n",
        "\n",
        "Adem√°s se agrega el gr√°fico PR el cual muestr una curva similar a la curva ideal de referencia que deben tener los gr√°ficos Precision/recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wli4-7J0lYTr"
      },
      "outputs": [],
      "source": [
        "#5. Calcule la precisi√≥n@k y el recall@k para valores de threshold que var√≠en entre 3.0 y 4.5, con paso de 0.1.\n",
        "# Luego, grafique los resultados y analice el comportamiento de las curvas de precisi√≥n y recall en funci√≥n de threshold\n",
        "new_step=[3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5]\n",
        "pre_2=[]\n",
        "recall_2=[]\n",
        "for i in new_step:\n",
        "  precisions, recalls = precision_recall_at_k(predictions_nmf, k=10, threshold=i)\n",
        "  mean_precision=np.mean([precision for precision in precisions.values()])\n",
        "  mean_recall=np.mean([recall for recall in recalls.values()])\n",
        "  pre_2.append(mean_precision)\n",
        "  recall_2.append(mean_recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tv1NmmsYlaCH",
        "outputId": "0dc0b7fe-8ddc-4484-b1bb-b364b4dfebc3"
      },
      "outputs": [],
      "source": [
        "#grafico precision\n",
        "fig = px.line(x=new_step, y=pre_2, title='Gr√°fico Precisi√≥n@k')\n",
        "fig.show()\n",
        "#grafico recall\n",
        "fig = px.line(x=new_step, y=recall_2, title='Gr√°fico Recall@k')\n",
        "fig.show()\n",
        "#grafio PR\n",
        "fig = px.line(x=recall_2, y=pre_2, title='Gr√°fico PR')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2zCkiI7UpGY"
      },
      "source": [
        "*Comentario*\n",
        "\n",
        "\n",
        "A medida que el threshold aumenta, el precision cae, pero con un cambio constante y no de manera abrupta. Por otro lado, el recall tambien disminuye lentamente.\n",
        "\n",
        "Adicionalmente se grafica la curva Precision/Recall la cual est√° alejada de ser una curva ideal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "k7SJFsOHUmM5"
      },
      "outputs": [],
      "source": [
        "#6Finalmente utilice el mejor modelo para estimar los ratings faltantes. Muestre sus resultados en una matriz (usuario, producto) sin valores nulos.\n",
        "\n",
        "# Get missing ratings, es decir los que tienen valor 0\n",
        "df_cervezas_pivot.replace(0, np.nan, inplace=True)\n",
        "missing_ratings = df_cervezas_pivot.isna()\n",
        "\n",
        "#recorro indice de userId y luego de beerId\n",
        "for userId in df_cervezas_pivot.index:\n",
        "  for beerId in df_cervezas_pivot.columns:\n",
        "    #si est√° NaN que realice la predi\n",
        "    if missing_ratings.loc[userId, beerId]:\n",
        "      df_cervezas_pivot.loc[userId, beerId] = model_nmf.predict(userId, beerId).est\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "bT3jcZWBWt4O",
        "outputId": "fe3cabf5-10c5-464b-9842-ee20f7eee34a"
      },
      "outputs": [],
      "source": [
        "df_cervezas_pivot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS418FVdIO97"
      },
      "source": [
        "# Conclusi√≥n\n",
        "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por el foro de U-cursos o por correo.\n",
        "\n",
        "<center>\n",
        "<img src =\"https://i.gifer.com/origin/cb/cbd80e6045652ab123caffef72f29210_w200.gif\" width = 400 />\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jKJ0AuRJpDa-",
        "Obay1DE6H9Hk",
        "6-aXIm9ZOufL",
        "4_RHVQbNvGKQ",
        "c7pMOOedwGQu",
        "oGCI_UeUwHcw",
        "rhYHlQYowqd_"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
